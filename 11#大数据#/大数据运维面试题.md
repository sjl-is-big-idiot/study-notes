hdfs/flume/kafka的调优，不仅限于这几个？

yarn的工作流程？

hdfs联邦的原理，每一个nn是不是都是单点的，如何解决单点故障的？

hive的查询原理

kafka partition的leader的选举原理

hdfs集群数据迁移怎么做？

hdfs中误删数据怎么恢复？除了回收站？

hdfs多租户的权限怎么设置/管理的？

如何做到多租户中存储和计算的隔离的？

yarn中的capacity调度器，若一个队列资源使用过大，影响了其他队列中的任务该怎么处理?

遇到了什么问题，怎么排查，怎么解决的？

如果一个flume采数据失败了，如何从之前的offset位置

zk的监听器，当子节点的子节点发生改变会触发通知吗？



##  Flume面试题整理（一）

### 1、Flume使用场景（☆☆☆☆☆）

  线上数据一般主要是落地（存储到磁盘）或者通过socket传输给另外一个系统，这种情况下，你很难推动线上应用或服务去修改接口，实现直接向kafka里写数据，这时候你可能就需要flume这样的系统帮你去做传输。

### 2、Flume丢包问题（☆☆☆☆☆）

  单机upd的flume source的配置，100+M/s数据量，10w qps flume就开始大量丢包，因此很多公司在搭建系统时，抛弃了Flume，自己研发传输系统，但是往往会参考Flume的Source-Channel-Sink模式。
  一些公司在Flume工作过程中，会对业务日志进行监控，例如Flume agent中有多少条日志，Flume到Kafka后有多少条日志等等，如果数据丢失保持在1%左右是没有问题的，当数据丢失达到5%左右时就必须采取相应措施。

### 3、Flume与Kafka的选取

  采集层主要可以使用Flume、Kafka两种技术。
  Flume：Flume 是管道流方式，提供了很多的默认实现，让用户通过参数部署，及扩展API。
  Kafka：Kafka是一个可持久化的分布式的消息队列。
  Kafka 是一个非常通用的系统。你可以有许多生产者和很多的消费者共享多个主题Topics。相比之下，Flume是一个专用工具被设计为旨在往HDFS，HBase发送数据。它对HDFS有特殊的优化，并且集成了Hadoop的安全特性。所以，Cloudera 建议如果数据被多个系统消费的话，使用kafka；如果数据被设计给Hadoop使用，使用Flume。
  正如你们所知Flume内置很多的source和sink组件。然而，Kafka明显有一个更小的生产消费者生态系统，并且Kafka的社区支持不好。希望将来这种情况会得到改善，但是目前：使用Kafka意味着你准备好了编写你自己的生产者和消费者代码。如果已经存在的Flume Sources和Sinks满足你的需求，并且你更喜欢不需要任何开发的系统，请使用Flume。
  Flume可以使用拦截器实时处理数据。这些对数据屏蔽或者过量是很有用的。Kafka需要外部的流处理系统才能做到。
  Kafka和Flume都是可靠的系统，通过适当的配置能保证零数据丢失。然而，Flume不支持副本事件。于是，如果Flume代理的一个节点奔溃了，即使使用了可靠的文件管道方式，你也将丢失这些事件直到你恢复这些磁盘。如果你需要一个高可靠性的管道，那么使用Kafka是个更好的选择。
  Flume和Kafka可以很好地结合起来使用。如果你的设计需要从Kafka到Hadoop的流数据，使用Flume代理并配置Kafka的Source读取数据也是可行的：你没有必要实现自己的消费者。你可以直接利用Flume与HDFS及HBase的结合的所有好处。你可以使用Cloudera Manager对消费者的监控，并且你甚至可以添加拦截器进行一些流处理。

### 4、数据怎么采集到Kafka，实现方式

  使用官方提供的flumeKafka插件，插件的实现方式是自定义了flume的sink，将数据从channle中取出，通过kafka的producer写入到kafka中，可以自定义分区等。

### 5、flume管道内存，flume宕机了数据丢失怎么解决

  1）Flume的channel分为很多种，可以将数据写入到文件。
  2）防止非首个agent宕机的方法数可以做集群或者主备。

### 6、flume配置方式，flume集群（详细讲解下）

  Flume的配置围绕着source、channel、sink叙述，flume的集群是做在agent上的，而非机器上。

### 7、flume不采集Nginx日志，通过Logger4j采集日志，优缺点是什么？

  优点：Nginx的日志格式是固定的，但是缺少sessionid，通过logger4j采集的日志是带有sessionid的，而session可以通过redis共享，保证了集群日志中的同一session落到不同的tomcat时，sessionId还是一样的，而且logger4j的方式比较稳定，不会宕机。
  缺点：不够灵活，logger4j的方式和项目结合过于紧密，而flume的方式比较灵活，拔插式比较好，不会影响项目性能。

### 8、flume和kafka采集日志区别，采集日志时中间停了，怎么记录之前的日志？

  Flume采集日志是通过流的方式直接将日志收集到存储层，而kafka是将缓存在kafka集群，待后期可以采集到存储层。
  Flume采集中间停了，可以采用文件的方式记录之前的日志，而kafka是采用offset的方式记录之前的日志。

### 9、flume有哪些组件，flume的source、channel、sink具体是做什么的（☆☆☆☆☆）

1）source：用于采集数据，Source是产生数据流的地方，同时Source会将产生的数据流传输到Channel，这个有点类似于Java IO部分的Channel。
2）channel：用于桥接Sources和Sinks，类似于一个队列。
3）sink：从Channel收集数据，将数据写到目标源(可以是下一个Source，也可以是HDFS或者HBase)。
**注意：要熟悉source、channel、sink的类型**



HDFS总结：
1、HDFS是如何解决大规模数据的存储和管理的

2、HDFS的架构原理和各核心组件的作用及关系

3、HDFS文件系统数据的读写流程

4、HDFS的HA的架构原理及核心

5、HDFS的Federation机制

6、HDSF的HA和Federation的区别
————————————————
版权声明：本文为CSDN博主「流一恩典」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/czz1141979570/article/details/103324881



当前你们公司使用的Hadoop版本是什么
HDFS常见的数据压缩格式有哪些，介绍其中一种详细的实现方式
HDFS垃圾回收的时间模式是多久，如何修改该时间
HDFS如何生效机架感知，取消机架感知有什么问题
HDFS常见的运维操作有哪些，哪些操作是高危的，如果高危操作出现问题，如何解决
HDFS常见的故障是什么，如何处理，是否可以给出三种预案来防范大部分常见故障
你经历过哪些严重的Hadoop故障
HDFS常用的IO压力测试工具有哪些
Hadoop哪些地方依赖于主机名，是否可以全部替换为IP呢（HDFS/YARN/SPARK）
HDFS有哪些核心的指标需要采集和监控，最重要的三个指标是什么
HDFS节点下线，如何提升其下线速度
HDFS常见的误删除数据场景，以及如何防止数据被误删除
HDFS集群对外提供的访问方式有几种，哪种最为常见，每种方式各自的优缺点和使用场景
HDFS你做过哪些性能调优，哪些是通用的，哪些是针对特定场景的
Hadoop日常的运维操作有什么管理工具，已经搭建的集群如何使用ambari
Hadoop各类角色如何进行扩容，缩容，节点迁移（IP变更）
Hadoop各类角色的JVM参数配置如何设定
HDFS的block大小如何设置，取决于哪些因素
YARN的nodemanager上跑任务的时候，有时候会将磁盘全部打满，如何解决
HDFS集群多个业务方使用时如何提前做好运维规划，如权限，配额，流量突增，数据安全，目录结构
HDFS中，小文件的定义是什么，如何对小文件进行统计分析，如何优化该问题
HDFS的namenode如何进行主备切换
YARN的nodemanager导致机器死机，如何解决
如何下线YARN的nodemanager节点，假如该节点持续在运行计算任务
YARN的nodemanager节点，从Active Nodes转为Lost Nodes，有哪些原因，在哪里设置
YARN的nodemanager节点如果转为Lost Nodes后，该节点上的计算任务是否还会正常继续
HDFS的快照原理简要介绍一下，为什么可以确保数据的安全性
YARN的yarn.nodemanager.local-dirs和yarn.nodemanager.log-dirs参数应该如何设置，有哪些常见的问题
distcp拷贝数据的时候，出现了java.lang.outofmemoryerror:java heap space，如何处理
有两个hadoop集群，机器相同，磁盘占用相同，一个集群磁盘的使用率比较均匀，另一个集群磁盘使用率起伏较大（很多写满的，很多使用率很低的），那么第二个集群会有哪些问题
hdfs namenode启动慢，常见的原因有哪些？如何优化？
hadoop的hdfs、yarn配置的zookeeper，是否可以分开
————————————————
版权声明：本文为CSDN博主「焦振清」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_43947499/article/details/84790685





# [大数据运维方向面试题](https://www.cnblogs.com/feng-bigdata/p/7705083.html)

  **一、基础题**

**1.请写出http和https请求的区别，并写出遇到过的响应状态码.**

 

**一、https协议需要到ca申请证书，一般免费证书很少，需要交费。**

**二、http是超文本传输协议，信息是明文传输，https 则是具有安全性的ssl加密传输协议。 三、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。**

**四、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。**

 

**状态码常用：**

**301 永久重定向**

**403 服务器已经理解请求，但是拒绝执行**

**404 页面丢失**

**500 服务器错误**

 

 

**2.请写出在linux系统上面搭建系统或者产品等大数据平台需要对系统进行哪些检查。**

**从稳定性说：需要检查集群中的每一台服务器的命令安装是否完善，环境变量是否配置完毕，每一台服务器的软件配置是否有问题。**

**扩展性: 能够快速扩展机器，横向扩展条件是否具备**

 

 

**3.请写出使用过的linux系统有哪些版本，如何查看系统信息？（发行版本，内核版本等信息）。**

**Centos 6.5 6.6 x64 1.查看发行版本命令：cat /etc/issue**

 **2.查看内核版本：  cat /proc/version**

 

 

**4.请使用命令在linux系统中创建用户test，用户组为test1，用户目录 /test , 并赋予sudo权限。**

**useradd -d /test -m test -g test1 -G root**

 

**useradd 选项 用户名 其中各选项含义如下：**

**-c comment 指定一段注释性描述。**

**-d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。**

**-g 用户组 指定用户所属的用户组。**

**-G 用户组，用户组 指定用户所属的附加组。**

**-s Shell文件 指定用户的登录Shell。**

**-u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。**

 

**Sudo可以修改文件需要root用户**

**sudo的工作过程如下：**

 **1，当用户执行sudo时，系统会主动寻找/etc/sudoers文件，判断该用户是否有执行sudo的权限**

 **2，确认用户具有可执行sudo的权限后，让用户输入用户自己的密码确认**

 **3，若密码输入成功，则开始执行sudo后续的命令**

**4，root执行sudo时不需要输入密码(eudoers文件中有配置root ALL=(ALL) ALL这样一条规则)**

**5，若欲切换的身份与执行者的身份相同，也不需要输入密码**

 

 

 

**5.写出最少3个监控系统指标的命令（如内存，CPU ，IO，磁盘等）。**

**看内存 ：free**

**看cpu：more /proc/cpuinfo**

**看IO：iostat -x 10**

**看磁盘：fdisk -l**

 

 

**6.请用多种方式在linux系统中设置环境变量，并指出各种方式的区别。**

 

**1、控制台中设置，不赞成这种方式，因为他只对当前的shell 起作用，换一个shell设置就无效了： $PATH="$PATH":/NEW_PATH (关闭shell Path会还原为原来的path)**

 

**2、修改 /etc/profile 文件，如果你的计算机仅仅作为开发使用时推存使用这种方法，因为所有用户的shell都有权使用这个环境变量，可能会给系统带来安全性问题。这里是针对所有的用户的，所有的shell 在/etc/profile的最下面添加： export PATH="$PATH:/NEW_PATH"**

 

**3、修改bashrc文件，这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，这里是针对某一特定的用户，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的 .bashrc文件就可以了。 在下面添加： Export PATH="$PATH:/NEW_PATH"**

 

 

**7.请在linux系统中添加指定的定时任务。（每月1,15日，1,10点运行 /run.sh）.**

 

*** 1 ,10 1,15 \* \* sh /run.sh**

 

**8.编写个shell脚本将/data目录下大于100k的文件转移到 /tmp 目录下。**

**#! /bin/sh**

 

**directory=/data/\***

**filesize=0**

**for file in $directory**

 **do**

 **filesize=$(wc -c < $(basename $file))**

**if [ $filesize -gt 100\*1024 ]**

 **then**

**mv  $(basename $file)  /tmp**

 

**fi**

**done**

 

**9.请使用命令写出在linux系统中对于文件01.txt ，查找行内容包含“java”关键字，但不包含“bug”关键字的内容，不区分大小写。**

**:set ignorecase 忽略大小写 然后执行命令  /java[^bug]** 

 

**10.请帮我查询出8443端口正在被哪个进程使用？**

**netstat -tunlp|grep 8443**

 

 

**11.请在linxu系统中使用命令快速找出mysql文件的位置。**

 

**rpm -qal |grep mysql**

 

**12.搭建NFS文件共享服务，如共享目录为 /nfs , 如何配置NFS服务，客户端怎么挂载共享目录。**

**1.  yum install nfs-utils rpcbind 安装NFS服务端**

**2.  vi /etc/sysconfig/nfs 搜索和设置如下所示的端口配置：**

 **RQUOTAD_PORT=30001**

**LOCKD_TCPPORT=30002**

 **LOCKD_UDPPORT=30002**

 **MOUNTD_PORT=30003**

**STATD_PORT=30004**

**3.关闭防火墙**

**4.vi /etc/selinux/config 将上述文件中的 SELINUX=enforcing 替换为 SELINUX=permissive 保存上述文件之后，运行以下命令： setenforce 0**

**5、创建共享目录 mkdir /home/nfs-share**

**6、vi /etc/exports 在上述文件的末尾新增一行，如下所示：**

 **/data/nfs_share 192.168.4.212(rw,sync,no_root_squash)**

**/data/nfs_share \*(ro) 这一行表示只有192.168.4.212客户端能够以读写权限挂载共享目录，其他客户端只能以只读权限挂载。**

**7.启动chkconfig nfs on**

​    **chkconfig rpcbind on**

**service nfs start**

**service rpcbind start**

**8. yum install -y nfs-utils**

**9.手动挂载NFS共享目录**

**Step-1：确定挂载点，运行以下命令： showmount -e 192.168.4.211**

**-e选项显示NFS服务端的导出列表。**

**Step-2：创建挂载目录，运行以下命令： mkdir -p /root/remote_dir 其中，/root/remote_dir为共享目录的挂载点目录。**

 **Step-3：挂载共享目录，运行以下命令： mount -t nfs 192.168.4.211:/data/nfs_share /root/remote_dir 其中，-t选项用于指定文件系统的类型为nfs。**

 **Step-4：共享目录使用结束之后，卸载共享目录，运行以下命令： umount /root/remote_dir**

 

 

 

**13.解释以下vi命令的意思，根据意思写出vi命令。**

**1） :s/p1/p2/g   将所有的p1替换成p2**

**2) 显示行号    :set nu**

**3） p       粘贴  对应 nyy复制使用**

**4)  删除光标下6行 6dd**

**5） 将光标移动到最后一行行首  G**

**6） /apple       查找apple字符串**

 

 

**14.是否搭建过大数据组件相关的集群，如果集群之间无法通信了，怎么排查？**

 

**搭建过，应该检查 1. jps查看进程是否停止**

​         **2. 检查ip是否ping通**

 

 

**15.是否安装过mysql源码版本，写出安装流程。**

 

**Mysql5.6安装**

**一 编译环境安装**

**1、安装make编译器**

**2、安装 bison**

**3、安装gcc-c ++**

**4、安装cmake**

**5、安装ncurses**

**6、 yum install gcc gcc-c++**

**yum install -y ncurses-devel**

**yum install -y cmake**

**yum install -y libaio**

**yum install -y bison**

**二 mysql安装**

 **1、解压mysql源码压缩文件**

 **2、编译完成配置mysql服务**

 **3、启动mysql**

 **4、修改root密码（默认为空）**

 

 

 

**16.有下列两表：**

**TAB1**

**C1      C2**              

**------    - -----**

**A       11**

**B       12**

**C       13**

**TAB2**

**CX      CY**

**------     ------**

**A       21**

**C       22**

**D       23**

**要得到一下结果：**

 

**C1   C2   CX    CY**

**-----  -----   ------   ------**

 

**A   11    A     21**

 

**C   13    C     22**

 

**-----  ------   D     23**

 

**请写出具体的sql语句**

 

**SELECT \* from tab1 RIGHT JOIN tab2 on tab1.C1 =tab2.CX**

 

**Union是连接两个查询语句 （select \* from tab1 union all select \* from tab2）**

**Union ALL 连接所有值包括重复  Union不包括重复值**

 

**二、基础题**

**1、请写出mysql数据库的几种备份/恢复方法。并指出其优缺点**

**备份**

**1、linux命令 mysqldump 直接生成.sql文件备份**

**mysqldump -u username -p dbname table1 > /home/BackupName.sql  输出mysql密码后备份**

**2.利用工具备份（Navicat）**

**3.复制整个数据库目录备份 （xcopy 命令）**

**4.使用mysqlhotcopy工具快速备份（热备份）**

**原理：先将需要备份的数据库加上一个读锁，然后用FLUSH TABLES将内存中的数据写回到硬盘上的数据库，最后，把需要备份的数据库文件复制到目标目录。**

**恢复：**

**mysql -u root -p dbname < C:\backup.sql**

 

**优缺点：**

**1.Mysqldump：利用linux或者shell进行备份比较灵活，运行较慢**

**2.利用工具：不好控制，不能自定义**

**3.复制整个data目录 ：这种方法不适用于InnoDB存储引擎的表，而对于MyISAM存储引擎的表很方便。同时，还原时MySQL的版本最好相同。**

**4.mysqlhotcopy：mysqlhotcopy支持不停止MySQL服务器备份。而且，mysqlhotcopy的备份方式比mysqldump快。mysqlhotcopy是一个perl脚本，主要在Linux系统下使用。其使用LOCK TABLES、FLUSH TABLES和cp来进行快速备份。需要安装Perl和DBI支持。**

**2、请解释max_allowed_packet 的用途**

**指代mysql服务器端和客户端在一次传送数据包的过程当中数据包的大小这个是定义mysql服务器端和客户端在一次传送数据包的过程当中数据包的大小定义过大，比如max_allowed_packet=8092，有可能服务器端太忙，来不及接收，或者网络太差，会容易造成丢包定义过小，会因为客户端可能无法快速接收服务器端发过来的包，一般推荐是4096**

 

**3、写出调优过的mysql配置参数（连接数/接收的数据包大小）**

 

**MySQL配置文件my.cnf**

**global max_connections 设置连接数**

**max_allowed_packet  客户端与服务端之间一次传输数据包大小**

**。。。。**

**4、查看linux系统中启动了多少java进程，并获取其中某个java进程的内存使用情况。**

**Jps 查看进程pid**

**jmap -heap pid**

 

**5、指出Nginx支持哪几种负载均衡模式，并指出各模式的应用场景。**

**1.roundrobin 轮询方式，依次将请求分配到各个后台服务器中，默认的负载均衡方式。 适用于后台机器性能一致的情况。 挂掉的机器可以自动从服务列表中剔除。**

 **2.weight 根据权重来分发请求到不同的机器中，适用于后台机器性能不一样的情况。**

 **3.ip_hash 根据请求者ip的hash值将请求发送到后台服务器中，可以保证来自同一ip的请求被打到固定的机器上，可以解决session问题。**

 **4.url_hash 根据请求的url的hash值将请求分到不同的机器中，当后台服务器为缓存的时候效率高。**

 **5.fair 根据后台响应时间来分发请求，响应时间短的分发的请求多。**

 

**三、专项题**

**1.写出hadoop集群常用进程以及进程含义**

**1、Namenode**

**它是Hadoop 中的主服务器，管理文件系统名称空间和对集群中存储的文件的访问。**

**2、Datanode**

**它负责管理连接到节点的存储（一个集群中可以有多个节点）。每个存储数据的节点运行一个 datanode 守护进程。**

**3、secondaryNameNode**

**它不是 namenode 的冗余守护进程，而是提供周期检查点和清理任务。 出于对可扩展性和容错性等考虑，我们一般将SecondaryNameNode运行在一台非NameNode的机器上。**

**4、ResourceManager**

**负责调度 DataNode上的工作。每个 DataNode有一个NodeManager，它们执行实际工作。**

**5、NodeManager**

**负责执行ResourceManager分发的任务**

**HA 模式忽略**

**2.Hadoop安装部署需要修改的配置文件，以及常用端口，举例说明**

**hadoop-env.sh  hadoop jdk配置**

**core-site.xml   hadoop核心文件-配置hadoop的命名服务和tmp目录和zookeeper集群**

**hdfs-site.xml   配置通信端口 http端口等。**

**mapred-site.xml  配置mapreduce的资源调度框架 yarn**

**yarn-site.xml   yarn相关配置**

**Slaves 文件    指定hadoop集群的子节点位置**

**端口：**

**50070  namenode的web访问端口**

**9000  RPC通信端口**

**2181  zookeeper端口** 

**...**

**3.使用过的hadoop shell 命令**

**Hadoop fs -ls /**

**Hadoop fs -mkdir /test**

**Hadoop fs -cat /**

**.......**

作者：牛客817517800号
链接：https://www.nowcoder.com/discuss/718107?source_id=discuss_experience_nctrack&channel=-1
来源：牛客网



### 字节date数据中台 实习一面（8-17，47min） 

 自我介绍 

 [项目]()（两个[项目]()都问了） 

 数据倾斜问题怎么解决 

 MR 过程中有几次[排序]()过程 

 sql：公交车人数最高的时间段 

 [算法]()：[二叉树]()层次遍历 

 一个男孩，一个女孩的概率问题 

 瓶盖换水问题 

 维度建模步骤 

1.  选择业务处理 
2.  定义粒度 
3.  选择维度 
4.  确定事实 

   

###  字节date数据中台 二面（8.20 1h 7min） 

 自我介绍 

 根据自我介绍聊天（聊了很多） 

 离线处理和实时处理的区别 

 主要考察 wordcount 细节 

 Map默认是HashPartitioner 如何自定义分区 

 hadoop 三大组件简介 

 SeconderyNameNode 的作用 

 计算机基础知识系列 

 数据库索引 InnoDB 数据引擎的特点 

 事务的隔离级别 

 数据库 三大范式 

 tcp 为什么是三次握手 

 tcp 如何保证可靠性连接 

 网络7层架构，各个层都是干什么的 

 ![preview](大数据运维面试题.assets/56_1568900435177_29C080A5413E925FE3B3CCB4048AB99B) 

 [算法题]() 

 非严格单调递增 查找最靠前的目标数 

 [二叉树]()前序遍历 

###  字节 data数据中台 三面（8.23 50min） 

 主要是对知识的理解深度 

 如何学习的大数据相关的知识 

 介绍一下 YARN 

 YARN 的任务提交流程 

 有没有读过 MapReduce 相关的论文 

 Mapreduce 为什么适合适合大数据存储 

 PB级大数据处理时，比如join操作，如何优化 

 job， task，work 的区别（涉及spark 不会） 

 在集群计算的时候，什么是集群的主要瓶颈（磁盘IO（正解），CPU，内存，网络带宽） 

 MapReduce 处理过程 

 sql （比较简单，但我没转过来） 

 Hive 内部表和外部表的区别 

###  字节数据中台 HR面（8.24 20min） 

 自我介绍 

 怎么学习的大数据 

 相对于专业大数据有什么有时 

 业务结合能力强吗 

 办公地地点 

 有没有面过别的地方 

 反问 

 实习时间几点到几点 

 薪资待遇





作者：Richard_$
链接：https://www.nowcoder.com/discuss/732950?source_id=discuss_experience_nctrack&channel=-1
来源：牛客网



一面 电话 50min 

  飞猪数据组 偏向平台建设方向 

  1.自我介绍 

  2.研究生[项目]() 

  3.流计算 

  4.java内存模型 

  5.垃圾回收 

  6.什么时候发生fullGC 

  7.怎么判断是垃圾 

  8.数据结构了解哪些 

  9.[链表]()、数组的区别 

  10.mysql为什么选用B+树 

  11.能否估计下b+树做索引的整个表的大小 

  12.mr、spark的shuffle有什么不同 

  13.宽依赖是什么 

  14.什么情况下需要划分宽依赖，哪些算子，groupby是行动算子吗 

  15.mr里join怎么做（说的spark的join） 

  16.shuffle-join和sort-join使用场景有什么不同 

  17.一千万个整数，在5mb内存里[排序]() 

  反问： 

  1.最后一题不分治怎么解决：用数据压缩计算 

  2.介绍下部门：飞猪数据组，涉及数仓、数据科学家、平开



