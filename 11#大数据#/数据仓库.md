- 偏数仓：SQL boy
- 偏平台：etl工具、计算引擎、数据中间件。

# 1. 大数据平台——通用架构及技术体系

参考文章：https://baijiahao.baidu.com/s?id=1761450434038117412&wfr=spider&for=pc

​					https://cloud.tencent.com/developer/article/1099120?areaSource=106002.1

在传统的分布式系统中，常用的存储计算架构有如下三种。

![架构](数据仓库.assets/p386152.png)

- Shared Disk/Storage （共享存储）

  有一个分布式的存储集群，每个计算节点像访问单机数据一样访问这个共享存储上的数据。这种架构的存储层可以比较方便的扩展，但是计算节点需要引入分布式协调机制保证数据同步和一致性，因此计算节点的可扩展性有一个上限。

- Shared Nothing

  每个计算节点自己挂载存储，一个节点只能处理一个分片的数据，节点之间可以通信，最终有一个汇总节点对数据进行汇总。这种架构能比较方便的扩展，但是它的缺点是节点Failover需要等待数据加载完成之后才能提供服务；并且存储和计算需要同时扩容，不够灵活，扩容后，有漫长的数据Rebalance过程。

- Storage Disaggregation（存储计算分离架构）

  存储和Shared Storage类似，有一个分布式的共享存储集群，计算层处理数据的模式和Shared Nothing类似，数据是分片的，每个Shard只处理自己所在分片的数据，每个计算节点还可以有本地缓存。

  存储计算分离的架构存在以下优势。

  - 一致性问题处理简单：计算层只需要保证同一时刻有一个计算节点写入同一分片的数据。
  - 扩展更灵活：计算和存储可以分开扩展，计算不够扩计算节点，存储不够扩存储节点。这样在大促等场景上会非常灵活。计算资源不够了，马上扩容计算就好了，不需要像Shared Nothing那样做耗时耗力的数据Rebalance；也不会像Shared Nothing那样，出现单机的存储容量瓶颈。
  - 计算节点故障恢复快：计算节点发生Failover之后，数据可以按需从分布式的共享存储异步拉取。因此Failover的速度非常快。

  

数据分析的结果对决策、业务发展有着举足轻重的作用。

传统数仓基本都是基于关系型数据库实现的，存在**痛点**：

- 非结构化、半结构化数据处理乏力
- ETL与业务强绑定
- 非结构化、半结构化数据要解析内容进行进入数仓，需要非常复杂的ETL
- 数据量过大（TB/PB级时），易出现性能瓶颈
- 三范式着力于解决数据冗余，目的是保障数据一致性。范式约束降低了数仓的性能。
- ETL对数据的处理，导致机器学习部分获取的数据为处理后的数据，可能存在失真，效果不理想的情况。在数据入库经过ETL时，就需要明确定义需要提取的特征数据，否则无法结构化入库。

## 数据仓库架构的演变

![img](数据仓库.assets/v2-6418d1b9c30aad1acb570374844f0f37_720w.webp)

因此，就引入了大数据平台来解决传统数据的痛点。当然**Hadoop大数据平台也有自己的问题**：

- 从数据仓库升级到大数据架构，是不具备平滑演进的，基本等于推翻重做。
- 大数据下的分布式存储强调数据的只读性质，所以类似于Hive，HDFS这些存储方式都不支持update，HDFS的write操作也不支持并行，这些特性导致其具有一定的局限性。

大数据平台是一种集成了多种大数据技术的系统，用于存储、管理、处理和分析大规模、高速、多源的数据。大数据平台通常包括**数据采集**、**数据存储**、**数据处理**、**数据分析**、**数据可视化**和**数据安全**等组件，可以帮助用户深入挖掘数据中的价值，支持决策制定和业务创新。

## **传统大数据架构**

![img](数据仓库.assets/inryf57fat.jpeg)

数据分析的业务没有发生任何变化，但是因为数据量、性能等问题导致系统无法正常使用，需要进行升级改造，那么此类架构便是为了解决这个问题。此为离线计算架构。

**优点：**简单，易懂，对于BI系统来说，基本思想没有发生变化，变化的仅仅是技术选型，用大数据架构替换掉BI的组件。

**缺点：**对于大数据来说，没有BI下如此完备的Cube架构，虽然目前有kylin，但是kylin的局限性非常明显，远远没有BI下的Cube的灵活度和稳定度，因此对业务支撑的灵活度不够，所以对于存在大量报表，或者复杂的钻取的场景，需要太多的手工定制化，同时该架构依旧以批处理为主，缺乏实时的支撑。

**适用场景：**数据分析需求依旧以BI场景为主，但是因为数据量、性能等问题无法满足日常使用。

## **流式架构**

![img](数据仓库.assets/6ysfp7tvnj.jpeg)

在传统大数据架构的基础上，流式架构非常激进，直接拔掉了批处理，数据全程以流的形式处理，所以在数据接入端没有了ETL，转而替换为数据通道。经过流处理加工后的数据，以消息的形式直接推送给了消费者。虽然有一个存储部分，但是该存储更多的以窗口的形式进行存储，所以该存储并非发生在数据湖，而是在外围系统。

**优点：**没有臃肿的ETL过程，数据的实效性非常高。

**缺点：**对于流式架构来说，不存在批处理，因此对于数据的重播和历史统计无法很好的支撑。对于离线分析仅仅支撑窗口之内的分析。

**适用场景：**预警，监控，对数据有有效期要求的情况。

## **Lambda架构**

![img](数据仓库.assets/08e5o8kswx.jpeg)

Lambda架构算是大数据系统里面举足轻重的架构，大多数架构基本都是Lambda架构或者基于其变种的架构。Lambda的数据通道分为两条分支：实时流和离线。实时流依照流式架构，保障了其实时性，而离线则以批处理方式为主，保障了最终一致性。什么意思呢？流式通道处理为保障实效性更多的以增量计算为主，而批处理则对数据进行全量运算，保障其最终的一致性，因此Lambda最外层有一个实时层和离线层合并的动作，此动作是Lambda里非常重要的一个动作。

**优点：**既有实时又有离线，对于数据分析场景涵盖的非常到位。

**缺点：**离线层和实时流虽然面临的场景不相同，但是其内部处理的逻辑却是相同，因此有大量冗余和重复的模块存在。

**适用场景：**同时存在实时和离线需求的情况。

## **Kappa架构**

![img](数据仓库.assets/cpq6o5958v.jpeg)

Kappa架构在Lambda 的基础上进行了优化，将实时和流部分进行了合并，将数据通道以[消息队列](https://cloud.tencent.com/product/cmq?from=20065&from_column=20065)进行替代。因此对于Kappa架构来说，依旧以流处理为主，但是数据却在数据湖层面进行了存储，当需要进行离线分析或者再次计算的时候，则将数据湖的数据再次经过消息队列重播一次则可。

**优点：** **Kappa架构解决了Lambda架构里面的冗余部分**，以数据可重播的超凡脱俗的思想进行了设计，整个架构非常简洁。

**缺点：**虽然Kappa架构看起来简洁，但是施难度相对较高，尤其是对于数据重播部分。

**适用场景：**和Lambda类似，改架构是针对Lambda的优化。

## **Unifield架构**![img](数据仓库.assets/ceanxgxqvq.jpeg)

以上的种种架构都围绕海量数据处理为主，Unifield架构则更激进，将机器学习和数据处理揉为一体，从核心上来说，Unifield依旧以Lambda为主，不过对其进行了改造，在流处理层新增了机器学习层。可以看到数据在经过数据通道进入数据湖后，新增了模型训练部分，并且将其在流式层进行使用。同时流式层不单使用模型，也包含着对模型的持续训练。

**优点：**Unifield架构提供了一套数据分析和机器学习结合的架构方案，非常好的解决了机器学习如何与数据平台进行结合的问题。

**缺点：**Unifield架构实施复杂度更高，对于机器学习架构来说，从软件包到硬件部署都和数据分析平台有着非常大的差别，因此在实施过程中的难度系数更高。

**适用场景：**有着大量数据需要分析，同时对机器学习方便又有着非常大的需求或者有规划。



**大数据平台的通用架构**

![img](数据仓库.assets/2934349b033b5bb589d7b591bc4c3932b700bc8c.jpeg@f_auto)

- 数据采集模块可以从多个数据源中获取数据，包括结构化数据、半结构化数据和非结构化数据，如传感器数据、设备数据、交易数据、文本数据等。
- 数据存储模块通常采用分布式文件系统或分布式数据库，如HDFS、Cassandra、HBase等。
- 数据处理模块可以对存储在数据仓库或数据湖中的数据进行分析和处理，如MapReduce、Spark等。
- 数据分析模块可以对处理后的数据进行挖掘和分析，如机器学习、数据挖掘等。
- 数据可视化模块可以将分析结果以可视化的方式展示给用户，如报表、图表等。
- 数据安全：负责保护数据的机密性、完整性和可用性，包括身份认证、访问控制、数据加密等技术。



**大数据的通用处理流程**

![img](数据仓库.assets/0bd162d9f2d3572cdb644e3e008c8f2c60d0c3fe.jpeg@f_auto)

大数据平台的**优点包括可以处理海量的数据，提供更准确的分析和预测，支持快速决策和业务创新，帮助企业降低成本和提高效率**。但是，**大数据平台的建设和运维需要较高的技术和成本投入**，需要根据具体业务场景进行规划和实施。



**大数据中的数仓体系架构**

![img](数据仓库.assets/a1ec08fa513d2697d9460190df645ef04116d895.jpeg@f_auto)



![img](数据仓库.assets/ac345982b2b7d0a26c41abeb41709a024a369a63.jpeg@f_auto)

## 阿里云分析服务一体化

![分析服务一体化数仓01](数据仓库.assets/分析服务一体化数仓01.png)

![分析服务一体化数仓02](数据仓库.assets/分析服务一体化数仓02.png)

![分析服务一体化数仓03](数据仓库.assets/分析服务一体化数仓03.png)

![分析服务一体化数仓04](数据仓库.assets/分析服务一体化数仓04.png)



![分析服务一体化数仓05](数据仓库.assets/分析服务一体化数仓05.png)

## 阿里云离线实时一体化数仓

![实时离线一体化概述01](数据仓库.assets/实时离线一体化概述01.png)



![实时离线一体化概述02](数据仓库.assets/实时离线一体化概述02.png)



![实时离线一体化概述03](数据仓库.assets/实时离线一体化概述03.png)



![实时离线一体化概述04](数据仓库.assets/实时离线一体化概述04.png)

![实时离线一体化概述05](数据仓库.assets/实时离线一体化概述05.png)





# 2. 数据仓库

转载自：[数据仓库和数据集市详解：ODS、DW、DWD、DWM、DWS、ADS](https://blog.csdn.net/weixin_42526326/article/details/121633372)

数仓笔记

数据仓库和数据集市详解：ODS、DW、DWD、DWM、DWS、ADS：https://blog.csdn.net/weixin_42526326/article/details/121633372

尚硅谷数仓实战之1项目需求及架构设计：https://blog.csdn.net/weixin_42526326/article/details/121658388

尚硅谷数仓实战之2数仓分层+维度建模：https://blog.csdn.net/weixin_42526326/article/details/121658605

尚硅谷数仓实战之3数仓搭建：https://blog.csdn.net/weixin_42526326/article/details/121658635

尚硅谷数据仓库4.0视频教程

B站直达：2021新版电商数仓V4.0丨大数据数据仓库项目实战：https://www.bilibili.com/video/BV1rL411E7uz

百度网盘：https://pan.baidu.com/s/1FGUb8X0Wx7IWAmKXBRwVFg ，提取码：yyds

阿里云盘：https://www.aliyundrive.com/s/F2FuMVePj92 ，提取码：335o

参考文章：http://webdataanalysis.net/web-data-warehouse/data-warehouse-frame/

## 数仓的基本架构

数据仓库的目的是构建面向分析的集成化数据环境，为企业提供决策支持（Decision Support）。其实数据仓库本身并不“生产”任何数据，同时自身也不需要“消费”任何的数据，数据来源于外部，并且开放给外部应用，这也是为什么叫“仓库”，而不叫“工厂”的原因。因此数据仓库的基本架构主要包含的是数据流入流出的过程，可以分为三层——**源数据**、**数据仓库**、**数据应用**：

[![data-warehouse-frame](数据仓库.assets/data-warehouse-frame.png)](http://webdataanalysis.net/wp-content/uploads/2010/08/data-warehouse-frame.png)

　　从图中可以看出数据仓库的数据来源于不同的源数据，并提供多样的数据应用，数据自下而上流入数据仓库后向上层开放应用，而数据仓库只是中间集成化数据管理的一个平台。

　　数据仓库从各数据源获取数据及在数据仓库内的数据转换和流动都可以认为是ETL（抽取Extra, 转化Transfer, 装载Load）的过程，ETL是数据仓库的流水线，也可以认为是数据仓库的血液，它维系着数据仓库中数据的新陈代谢，而数据仓库日常的管理和维护工作的大部分精力就是保持ETL的正常和稳定。

- 数仓中数据源的类型

  结构化、半结构化、非结构化数据。

  http://webdataanalysis.net/web-data-warehouse/data-warehouse-source-data/

- 数据仓库的数据存储

  (1).为什么不需要所有原始数据？数据仓库面向分析处理，但是某些源数据对于分析而言没有价值或者其可能产生的价值远低于储存这些数据所需要的数据仓库的实现和性能上的成本。比如我们知道用户的省份、城市足够，至于用户究竟住哪里可能只是物流商关心的事，或者用户在博客的评论内容可能只是文本挖掘会有需要，但将这些冗长的评论文本存在数据仓库就得不偿失；

  (2).为什么要存细节数据？细节数据是必需的，数据仓库的分析需求会时刻变化，而有了细节数据就可以做到以不变应万变，但如果我们只存储根据某些需求搭建起来的数据模型，那么显然对于频繁变动的需求会手足无措；

  (3).为什么要面向主题？面向主题是数据仓库的第一特性，主要是指合理地组织数据以方面实现分析。对于源数据而言，其数据组织形式是多样的，像点击流的数据格式是未经优化的，前台数据库的数据是基于OLTP操作组织优化的，这些可能都不适合分析，而整理成面向主题的组织形式才是真正地利于分析的，比如将点击流日志整理成页面（Page）、访问（Visit或Session）、用户（Visitor）三个主题，这样可以明显提升分析的效率。

  - 数据的聚合

    这里的聚合数据指的是基于特定需求的简单聚合（基于多维数据的聚合体现在多维数据模型中），简单聚合可以是网站的总Pageviews、Visits、Unique Visitors等汇总数据，也可以是Avg. time on page、Avg. time on site等平均数据，这些数据可以直接地展示于报表上。

  - 多维数据模型

    多维数据模型提供了多角度多层次的分析应用，比如基于时间维、地域维等构建的销售星形模型、雪花模型，可以实现在各时间维度和地域维度的交叉查询，以及基于时间维和地域维的细分。所以多维数据模型的应用一般都是基于联机分析处理（Online Analytical Process, OLAP）的，而面向特定需求群体的数据集市也会基于多维数据模型进行构建。

  - 业务模型

    这里的业务模型指的是基于某些数据分析和决策支持而建立起来的数据模型，比如我之前介绍过的用户评价模型、关联推荐模型、RFM分析模型等，或者是决策支持的线性规划模型、库存模型等；同时，数据挖掘中前期数据的处理也可以在这里完成。

- 数据仓库的数据应用
  - 报表展示

    报表几乎是每个数据仓库的必不可少的一类数据应用，将聚合数据和多维分析数据展示到报表，提供了最为简单和直观的数据。

  - 即席查询

    理论上数据仓库的所有数据（包括细节数据、聚合数据、多维数据和分析数据）都应该开放即席查询，即席查询提供了足够灵活的数据获取方式，用户可以根据自己的需要查询获取数据，并提供导出到Excel等外部文件的功能。

  - 数据分析

    数据分析大部分可以基于构建的业务模型展开，当然也可以使用聚合的数据进行趋势分析、比较分析、相关分析等，而多维数据模型提供了多维分析的数据基础；同时从细节数据中获取一些样本数据进行特定的分析也是较为常见的一种途径。

  - 数据挖掘

    数据挖掘用一些高级的算法可以让数据展现出各种令人惊讶的结果。数据挖掘可以基于数据仓库中已经构建起来的业务模型展开，但大多数时候数据挖掘会直接从细节数据上入手，而数据仓库为挖掘工具诸如SAS、SPSS等提供数据接口。

  - 元数据管理

    元数据（Meta Date），其实应该叫做解释性数据，即数据的数据。主要记录数据仓库中模型的定义、各层级间的映射关系、监控数据仓库的数据状态及ETL的任务运行状态。一般会通过元数据资料库（Metadata Repository）来统一地存储和管理元数据，其主要目的是使数据仓库的设计、部署、操作和管理能达成协同和一致。

  　最后做个Ending，数据仓库本身既不生产数据也不消费数据，只是作为一个中间平台集成化地存储数据；数据仓库实现的难度在于整体架构的构建及ETL的设计，这也是日常管理维护中的重头；而数据仓库的真正价值体现在于基于其的数据应用上，如果没有有效的数据应用也就失去了构建数据仓库的意义。

## 2.1 数据流向

![在这里插入图片描述](数据仓库.assets/53b53f017c0a4234903f65c638eb226a.png)

应用示例

![在这里插入图片描述](数据仓库.assets/bc618ee910e241d28b061d7d7cff3de5.png)

## 2.2 何为数仓DW

**Data warehouse**（可简写为DW或者DWH）数据仓库，是在数据库已经大量存在的情况下，它是一整套包括了`etl`、`调度`、`建模`在内的完整的**理论体系**。

数据仓库的方案建设的目的，是为前端查询和分析作为基础，主要应用于**OLAP（on-line Analytical Processing）**，支持复杂的**分析**操作，侧重**决策支持**，并且提供直观易懂的查询结果。目前行业比较流行的有：**AWS Redshift**，**Greenplum**，**Hive**等。

**数据仓库并不是数据的最终目的地**，而是为数据最终的目的地做好准备，这些准备包含：**清洗**、**转义**、**分类**、**重组**、**合并**、**拆分**、**统计**等

### 2.2.1 主要特点

#### 2.2.1.1 面向主题

操作型数据库组织面向事务处理任务，而数据仓库中的数据是按照一定的主题域进行组织。
主题是指用户使用数据仓库进行决策时所关心的重点方面，一个主题通过与多个操作型信息系统相关。

#### 2.2.1.2 集成

需要对源数据进行加工与融合，统一与综合
在加工的过程中必须消除源数据的不一致性，以保证数据仓库内的信息时关于整个企业的一致的全局信息。（关联关系）

#### 2.2.1.3 不可修改

DW中的数据并不是最新的，而是来源于其他数据源
数据仓库主要是为决策分析提供数据，涉及的操作主要是数据的查询

#### 2.2.1.4 与时间相关

处于决策的需要数据仓库中的数据都需要标明时间属性

### 2.2.2 与数据库的对比

|                | DW                                                           | 数据库                                                       |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
|                | 专门为数据分析设计的，涉及读取大量数据以了解数据之间的关系和趋势 | 用于捕获和存储数据                                           |
| 特性           | 数据仓库                                                     | 事务数据库                                                   |
| 适合的工作负载 | 分析、报告、大数据                                           | 事务处理                                                     |
| 数据源         | 从多个来源收集和标准化的数据                                 | 从单个来源（例如事务系统）捕获的数据                         |
| 数据捕获       | 批量写入操作通过按照预定的批处理计划执行                     | 针对连续写入操作进行了优化，因为新数据能够最大程度地提高事务吞吐量 |
| 数据标准化     | 非标准化schema，例如星型Schema或雪花型schema                 | 高度标准化的静态schema                                       |
| 数据存储       | 使用列式存储进行了优化，可实现轻松访问和高速查询性能         | 针对在单行型物理块中执行高吞吐量写入操作进行了优化           |
| 数据访问       | 为最小化I/O并最大化数据吞吐量进行了优化                      | 大量小型读取操作                                             |

## 2.3 为何要分层

数据仓库中涉及到的问题：

为什么要做数据仓库？
为什么要做数据质量管理？
为什么要做元数据管理？
数仓分层中每个层的作用是什么？
……
在实际的工作中，我们都希望自己的数据能够有顺序地流转，设计者和使用者能够清晰地知道数据的整个生命周期。

但是，实际情况下，我们所面临的数据状况很有可能是复杂性高、且层级混乱的，我们可能会做出一套表依赖结构混乱，且出现循环依赖的数据体系。

**为了解决我们可能面临的问题，需要一套行之有效的数据组织、管理和处理方法，来让我们的数据体系更加有序，这就是数据分层**。

**数据分层的好处**：

- 清晰数据结构：让每个数据层都有自己的作用和职责，在使用和维护的时候能够更方便和理解
- 复杂问题简化：将一个复杂的任务拆解成多个步骤来分步骤完成，每个层只解决特定的问题
- 统一数据口径：通过数据分层，提供统一的数据出口，统一输出口径
- 减少重复开发：规范数据分层，开发通用的中间层，可以极大地减少重复计算的工作

## 2.4 数据分层

参考文章：[数仓命名规范大全！](https://mp.weixin.qq.com/s/e_P8q9-B9QZUgwn0O7NBog)

每个公司的业务都可以根据自己的业务需求分层不同的层次；目前比较成熟的数据分层：

- 数据运营层ODS，**ODS(Operational Data Store)**
- 数据仓库层DW，**DW (Data Warehouse)**
  - DWD，**数据明细层：DWD  (Data Warehouse Detail)**
  - DWM，**数据中间层：DWM  (Data WareHouse Middle)**
  - DWS，**数据服务层：DWS  (Data WareHouse Servce)**
- 数据应用层ADS(APP)。

### 2.4.1 数据运营层ODS

数据运营层：`Operation Data Store` 数据准备区，也称为**贴源层**。**数据源中的数据，经过抽取、洗净、传输，也就是ETL过程**之后进入本层。该层的主要功能：

- ODS是后面数据仓库层的准备区
- 为DWD层提供原始数据(ETL之后的原始数据)
- 减少对业务系统的影响

在源数据装入这一层时，要进行诸如**去噪**（例如有一条数据中人的年龄是 300 岁，这种属于异常数据，就需要提前做一些处理）、**去重**(例如在个人资料表中，同一 ID 却有两条重复数据，在接入的时候需要做一步去重)、**字段命名规范**等一系列操作。

但是为了考虑后续可能需要追溯数据问题，因此对于这一层就不建议做过多的数据清洗工作，原封不动地接入原始数据也可以，根据业务具体分层的需求来做。

这层的数据是后续数据仓库加工数据的来源。**数据来源的方式**：

- 业务库
  经常会使用sqoop来抽取，例如每天定时抽取一次。
  实时方面，可以考虑用canal监听mysql的binlog，实时接入即可。
- 埋点日志
  日志一般以文件的形式保存，可以选择用flume定时同步
  可以用spark streaming或者Flink来实时接入
  kafka也OK
- 消息队列：即来自ActiveMQ、Kafka的数据等。

### 2.4.2 数据仓库层

数据仓库层从上到下，又可以分为3个层：`数据细节层DWD`、`数据中间层DWM`、`数据服务层DWS`。

#### 2.4.2.1 数据细节层DWD

数据细节层：`data warehouse details`，DWD(数据清洗/DWI)

**该层是业务层和数据仓库的隔离层**，保持和ODS层一样的数据颗粒度；主要是对ODS数据层做一些数据的清洗和规范化的操作，比如去除空数据、脏数据、离群值等。

为了提高数据明细层的易用性，该层通常会才采用一些维度退化方法，将维度退化至事实表中，减少事实表和维表的关联。

#### 2.4.2.2 数据中间层DWM

数据中间层：`Data Warehouse Middle`，DWM

该层是在DWD层的数据基础上，对数据做一些**轻微的聚合操作**，生成一些列的中间结果表，提升公共指标的复用性，减少重复加工的工作。

简答来说，对通用的核心维度进行聚合操作，算出相应的统计指标

#### 2.4.2.3 数据服务层DWS

数据服务层：`Data Warehouse Service`，DWS(宽表-用户行为，轻度聚合)

该层是基于DWM上的基础数据，**整合汇总成分析某一个主题域的数据服务层**，一般是**宽表**，用于提供后续的业务查询，OLAP分析，数据分发等。DWS层应覆盖 80%的应用场景 。又称**数据集市**或**宽表**。

一般来说，该层的数据表会相对较少；一张表会涵盖比较多的业务内容，由于其字段较多，因此一般也会称该层的表为**宽表**。

用户行为，轻度聚合对DWD
主要对ODS/DWD层数据做一些轻度的汇总。

### **2.4.3 数据应用层ADS**

数据应用层：`Application Data Service`，ADS(APP/DAL/DF)-**出报表结果**

该层主要是**提供给数据产品和数据分析使用的数据**，一般会存放在`ES`、`Redis`、`PostgreSql`等系统中供线上系统使用；也可能存放在`hive`或者`Druid`中，供数据分析和数据挖掘使用，比如常用的数据报表就是存在这里的。

**经过数据汇总层之后，应用层需要一个组件来存储结果数据，该组件一般是从 MySQL 数据库、KV 存储和 OLAP 引擎三者中选择其一。**如MySQL，HBase，Doris是分别这三个类型的代表。

### 2.4.4 事实表 Fact Table

事实表是指存储有事实记录的表，比如系统日志、销售记录等。事实表的记录在不断地增长，比如电商的商品订单表，就是类似的情况，所以事实表的体积通常是远大于其他表。

### 2.4.5 维表层Dimension（DIM）

维度表（`Dimension Table`）或维表，有时也称查找表（`Lookup Table`），是与事实表相对应的一种表；它保存了维度的属性值，可以跟事实表做关联，**相当于将事实表上经常重复出现的属性抽取、规范出来用一张表进行管理**。维度表主要是包含两个部分：

- **高基数维度数据**：一般是用户资料表、商品资料表类似的资料表，数据量可能是千万级或者上亿级别。高基数表示数据量较大
- **低基数维度数据**：一般是配置表，比如枚举字段对应的中文含义，或者日期维表等；数据量可能就是个位数或者几千几万。低基数表示数据量较小

### 2.4.6 临时表TMP

每一层的计算都会有很多**临时表**，专设一个DWTMP层来存储我们数据仓库的临时表。

## 2.5 数据集市

参考文章：https://www.oracle.com/cn/autonomous-database/what-is-data-mart/

**狭义ADS层； 广义上指hadoop从DWD DWS ADS 同步到RDS的数据。**

数据集市（`Data Mart`），也叫**数据市场**，**数据集市就是满足特定的部门**或者用户的需求，按照多维的方式进行存储，包括定义维度、需要计算的指标、维度的层次等，生成面向决策分析需求的数据立方体。

**Oracle官网对数据集市的解释**：

> [数据集市](https://www.oracle.com/cn/autonomous-database/departmental-data-warehouse/)是一种简单的数据仓库，专注于单个主题或业务线。借助数据集市，团队可以更快地访问数据并获取洞察，而不必花时间在更复杂的数据仓库中搜索或从不同的源手动汇总数据。
>
> **为什么要创建数据集市？**
>
> 数据集市可让您更轻松地访问组织内特定团队或业务线所需的数据。例如，如果您的营销团队需要数据来帮助改善假日季的营销活动绩效，筛选和组合分散在多个系统中的数据在时间、准确性和金钱上将涉及昂贵的成本。
>
> 团队被迫从各种来源查找数据，通常依赖电子表格来共享这些数据并开展协作。这通常会导致人为错误、混淆、复杂对账以及多个事实来源 — 就是所谓的“电子表格噩梦”。数据集市已成为创建报表、仪表盘和可视化之前，收集和组织必要数据的集中平台。
>
> **数据集市、数据湖和数据仓库之间的区别**
>
> 数据集市、数据湖和数据仓库满足不同的目的和需求。
>
> [**数据仓库**](https://www.oracle.com/cn/database/what-is-a-data-warehouse/)是一种数据管理系统，旨在为整个组织的商务智能和分析提供支持。数据仓库通常包含大量数据，包括历史数据。数据仓库中的数据一般来自应用日志文件和事务应用等广泛来源。数据仓库存储结构化数据，其用途通常已明确定义。
>
> [**数据湖**](https://www.oracle.com/cn/big-data/what-is-data-lake/)让组织存储大量结构化和非结构化数据（例如，来自社交媒体或点击流数据），并立即使其可用于实时分析、数据科学和机器学习用例。借助数据湖，无需进行更改，数据以原始形式摄取。
>
> 数据湖和数据仓库之间的主要区别在于，前者在没有预定义结构的情况下存储大量原始数据。组织不需要提前知道数据的用途。
>
> **[数据集市](https://www.oracle.com/cn/autonomous-database/departmental-data-warehouse/)**是一种简单的数据仓库形式，侧重于单个主题或业务线，例如销售、财务或营销。由于用途单一，数据集市从比数据仓库更少的来源中获取数据。 数据集市源可以包括内部操作系统、中央数据仓库和外部数据。数据集市源可以包括内部操作系统、中央数据仓库和外部数据。
>
> **我认为，数据集市可以看作是一个小的、简化的数据仓库，他只专注于单个主题，或主体域（例如按业务线划分主体域）。**

从范围上来说，数据是从企业范围的数据库、数据仓库，或者是更加专业的数据仓库中抽取出来的。数据中心的重点就在于它迎合了专业用户群体的特殊需求，在分析、内容、表现，以及易用方面。数据中心的用户希望数据是由他们熟悉的术语表现的。

带有数据集市的数据仓储结构

### 2.6 区别数据仓库

**数据集市就是企业级数据仓库的一个子集，它主要面向部门级业务，并且只面向某个特定的主题。为了解决灵活性与性能之间的矛盾，数据集市就是数据仓库体系结构中增加的一种小型的部门或工作组级别的数据仓库**。数据集市存储为特定用户预先计算好的数据，从而满足用户对性能的需求。数据集市可以在一定程度上缓解访问数据仓库的瓶颈。

理论上讲，应该有一个总的数据仓库的概念，然后才有数据集市。实际建设数据集市的时候，国内很少这么做。国内一般会先从数据集市入手，就某一个特定的主题（比如企业的客户信息）先做数据集市，再建设数据仓库。数据仓库和数据集市建立的先后次序之分，是和设计方法紧密相关的。而数据仓库作为工程学科，并没有对错之分。

在数据结构上，数据仓库是面向主题的、集成的数据的集合。而数据集市通常被定义为星型结构或者雪花型数据结构，数据集市一般是由一张事实表和几张维表组成的。

## 2.7 数仓建模

参考文章：https://blog.csdn.net/ytp552200ytp/article/details/124091557

推荐 https://mp.weixin.qq.com/s?__biz=MzIwNDI0ODY1OA==&mid=2655957891&idx=1&sn=bc83ec896f6397392f27ae2203c9d777&chksm=8d7910beba0e99a86e75655d1af7e0231e1fa2beef413657ccc5f07f3f6dae1aba8cb2ffc5ae&scene=27

常见的数仓命名规则：**前缀（ODS/DWD/MID）+主题域（user/shp）+业务类型+自定义表名+后缀（dd/ds/pi）**

![图片](数据仓库.assets/640)

![图片](数据仓库.assets/640)

### 2.7.1 建模方法论

> 数仓的建模或者分层，其实都是为了更好的去组织、管理、维护数据,所以当你站在更高的维度去看的话，所有的划分都是为了更好的管理。小到JVM 内存区域的划分，JVM 中堆空间的划分(年轻代、老年代、方法区等)，大到国家的省市区的划分，无一例外的都是为了更好的组织管理

- 访问性能：能够快速查询所需的数据，减少数据I/O。
- 数据成本：减少不必要的数据冗余，实现计算结果数据复用，降低大数据系统中的存储成本和计算成本。
- 使用效率：改善用户应用体验，提高使用数据的效率。
- 数据质量：改善数据统计口径的不一致性，减少数据计算错误的可能性，提供高质量的、一致的数据访问平台。

> 需要注意的建模其实是和公司的业务、公司的数据量、公司使用的工具、公司数据的使用方式密不可分的，因为模型是概念上的东西，需要理论落地至于落地到什么程度，就取决于公司的现状了

### 2.7.2 范式建模（关系型数据库）

范式建模法其实是我们在构建数据模型常用的一个方法，该方法的主要由Inmon所提倡，主要解决关系型数据库的数据存储，利用的一种技术层面上的方法，主要用于业务系统，所以**范式建模主要是利用关系型数据库进行数仓建设**

目前，**我们在关系型数据库中的建模方法，大部分采用的是三范式建模法**。

符合3NF要求的数据库设计，基本上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。

**数据库三范式**：https://blog.csdn.net/qq_52797170/article/details/125115139

- `第一范式(1NF)`主要是保证数据表中的每一个字段的值必须具有原子性，也就是数据表中的每个字段的值是不可再拆分的最小数据单元
- `第二范式(2NF)`要求在满足第一范式的基础上，还要满足数据表里的每一条数据记录，都是可唯一标识的，而且所有的非主键字段，都必须完全依赖主键，不能只依赖主键的一部分。
- `第三范式(3NF)`建立在已经满足第二范式的基础上。数据表中的每一个非主键字段都和主键字段直接相关，也就是说数据表中的所有非主键字段不能依赖于其他非主键字段，这个规则的意思是所有非主属性之间不能有依赖关系，它们是互相独立的。

**三范式**
**第一范式(1NF)**

属性值不可再分，说直白点就是一列里面不能包含多个小列，就像下面这样

![img](数据仓库.assets/0c23eb94892633333e6f5f8241c6698d.png)

**1NF是所有关系型数据库的最基本要求**，你在关系型数据库管理系统（`RDBMS`），例如`SQL Server`，`Oracle`，`MySQL`中创建数据表的时候，如果数据表的设计不符合这个最基本的要求，那么操作一定是不能成功的。也就是说，只要在RDBMS中已经存在的数据表，一定是符合1NF的

**第二范式(2NF)**

这里我们先说一下，为什么有了第一范式，还需要第二范式，那是因为**第一范式，不能消除重复，存在数据冗余过大，导致插入异常，删除异常，修改异常的问题**

![img](数据仓库.assets/9e2651aea1a00f50a594d9c8552846f6.png)

所以**要求每张表都要有一个主键，其它字段(列)完全依赖主键**，也就是说要求实体的属性完全依赖于主关键字。也就是说表只描述一个事实，因为这账号表描述了3个事实，学生、课程、和系

> 例如，如果花名册里只有名字，没有学号，则重名的话会很麻烦。
> **所谓完全依赖是指不能存在仅依赖主关键字一部分的属性**，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系，例如上面的系主任和系名 就是不依赖学号的，所以这里应该单独拆出来

**第三范式(3NF)**

**所有字段只能直接依赖主键**，不得依赖于其它字段(非主属性) 消除**依赖传递**。所谓传递函数依赖指的是如果存在"A-->B-->C"的决定关系，则C传递函数依赖于A。也就是说表中的字段和主键直接对应不依靠其他中间字段，说白了就是，**决定某字段值的必须是主键，而不是一个依赖于主键的其他字段**

**范式建模的优缺点**
优点:

- 节约存储(尤其是利用数据库进行数仓建设的时候)

- 规范化带来的好处是通过减少数据冗余提高更新数据的效率，同时保证数据完整性。
- 结构清晰，易于理解

缺点:

- 构建比较复杂
- 查询复杂(需要很多的关联)
- 不适合在大数据环境下构建(1 查询复杂  2 存储很便宜)

> 由于建模方法限定在关系型数据库之上，在某些时候反而限制了整个数据仓库模型的灵活性，性能等，特别是考虑到数据仓库的底层数据向数据集市的数据进行汇总时，需要进行一定的变通才能满足相应的需求。

**为什么要学习范式建模**

- 上游数据源往往是业务数据库，而这些业务数据库采用的是范式建模，所以了解范式建模可以帮助我们去合理的建设数仓
- 如果了解范式建模，从`ER模型`可以了解到数据架构，例如一个电商系统，从`ER模型`就可以知道哪些涉及到商品的管理、用户的管理、订单管理，拿到这些关系之后，我们就可以更好的进行数仓管理与建设
- 数据源的规范定义需要我们了解范式理论，可以更好的和业务系统进行对接
- 数仓的稀有系统，如报表系统设计的时候也会使用到范式建模
  

### 2.7.3 ER建模

将事物抽象为"实体"（Entity）、"属性"（Property）、"关系"（Relationship）来表示**数据关联和事物描述**，这种**对数据的抽象建模**通常被称为ER实体关系模型。

实体建模法并不是数据仓库建模中常见的一个方法，它来源于哲学的一个流派。

从哲学的意义上说，客观世界应该是可以细分的，**客观世界应该可以分成由一个个实 体，以及实体与实体之间的关系组成**。我们在数据仓库的建模过程中完全可以引入这个抽象的方法，**将整个业务也可以划分成一个个的实体，而每个实体之间的 关系**，以及针对这些关系的说明就是我们数据建模需要做的工作。

> 在日常建模中，"实体"用矩形表示，"关系"用菱形，"属性"用椭圆形。ER实体关系模型也称为`E-R关系图`
>
> 虽然实体法粗看起来好像有一些抽象，其实理解起来很容易。即我们可以**将任何一个业务过程划分成 3 个部分，实体，事件和说明**。

描述一个简单的事实：“小明开车去学校上学”。以这个业务事实为例，我们可以把“小明”，“学校”看成是一个实体， “上学”描述的是一个业务过程，我们在这里可以抽象为一个具体“事件”，而“开车去”则可以看成是事件“上学”的一个说明。

**应用场景**
ER模型是数据库设计的理论基础，当前几乎所有的`OLTP`系统设计都采用ER模型建模的方式。

Bill Inom提出的数仓理论，推荐采用ER关系模型进行建模。

**BI架构提出分层架构，数仓底层ods、dwd也多采用ER关系模型进行设计。**

>  由于实体建模法，能够很轻松的实现业务模型的划分，因此，在业务建模阶段和领域概念建模阶段，实体建模法有着广泛的应用。

**业务归纳**
使用的抽象归纳方法其实很简单，任何业务可以看成 3 个部分：

- 实体，主要指领域模型中特定的概念主体，指发生业务关系的对象

- 事件，主要指概念主体之间完成一次业务流程的过程，特指特定的业务过程

- 说明，主要是针对实体和事件的特殊说明
  

### 2.7.4 维度建模

维度模型是数据仓库领域大师`Ralph Kimball` 所倡导，他的《数据仓库工具箱》，是数据仓库工程领域最流行的数仓建模经典。维度建模以分析决策的需求出发构建模型，构建的数据模型为分析需求服务，因此它重点解决用户如何更快速完成分析需求，同时还有较好的大规模复杂查询的响应性能。

维度建模源自数据集市，**主要面向分析场景** **Ralph Kimball 推崇数据集市的集合为数据仓库**，同时也提出了对数据集市的维度建模，将数据仓库中的表划分为**事实表**、**维度表**两种类型。

一般也称之为**星型结构建模**，有时也加入一些**雪花模型**在里面。**维度建模是一种面向用户需求的、容易理解的、访问效率高的建模方法**

> 维度模型通常以一种被称为**星型模式**的方式构建。所谓星型模式，就是以一个事实表为中心，周围环绕着多个维度表。
>
> 还有一种模式叫做**雪花模式**，是对维度做进--星型模型做OLAP分析很方便

**为什么选择维度建模**

- 适配大数据的处理方式

  维度模型的非强范式的，可以更好的利用大数据处理框架的处理能力，避免范式操作的过多关联操作，可以实现高度的并行化。

  数据仓库大多数时候是比较适合使用星型模型构建底层数据Hive表，通过大量的冗余来提升查询效率，**星型模型对OLAP的分析引擎支持比较友好**，这一点在`Kylin`中比较能体现。

  **雪花模型**在关系型数据库中如MySQL，Oracle中非常常见，尤其像电商的数据库表。

- 自下而上的建设现状

  表已经存在，业务已经开发完毕，需求直接提过来了，这几乎是一个普遍现状，因为很少有公司会提前成立数据部门，让数据部门跟随着业务从头开始一直成长，都是当业务发展到一定的阶段了，想通过数据来提高公司的运营效果

- 简单的模型 使用简单

  这个模型相对来说是比较简单的，简单主要体现在两个方面

  - 维度建模非常直观，紧紧围绕着业务模型，可以直观的反映出业务模型中的业务问题。不需要经过特别的抽象处理，即可以完成维度建模。这一点也是维度建模的优势。

  - 星型结构的实现不用考虑很多正规化的因素，设计与实现都比较简单。

**分层和建模的关系**

- 明细层的范式模型

  明细层采用传统的三范式关系模型。这一层次的数据模型要将业务过程描述清楚，将源数据（即业务系统）中隐含的、有歧义的概念进行清晰化，如活跃用户、VIP用户等。该层次的数据模型追求的目标是灵活地表达业务过程，要保证数据一致性、唯一性、正确性，以尽量少的代价与源数据保持数据同步，同时该层次的数据模型不建议开给不懂技术的业务人员直接使用，因此，采用关系型的三范式模型是最佳的选择。

- 集市层的维度模型

  集市层是按照业务主题、分主题构建出来的、面向特定部门或人员的数据集合，该层次的数据模型会开放给业务人员使用，进行数据挖掘及业务分析。由于业务员多数不懂数据库技术，缺少将业务需求转换为关系型数据结构的逻辑思维，更写不出复杂的SQL语句，因此，越简单的数据模型，越能被他们所接受，因此，这个层次所构建出来的数据模型，要按照业务过程进行组织，每个事实表代表一个独立的业务过程，事实表之间不存在直接的依赖关系，这样业务人员可以很容易地将分析需求对应到事实表上，利用工具或手工写出简单的SQL，将统计数据提取出来进行分析。

**模型实现**
模型的实现主要指的是在维度建模过程中，需要对维度表和事实表进行关联设计，而这里我们对维度表的设计，就决定了我们最终与事实表关联的之后的形态。也就是说我们可以根据事实表和维度表的关系，又可将常见的模型分为**星型模型**和**雪花型模型**

星型模型和雪花模型的**主要区别在于对维度表的拆分，对于雪花模型，维度表的设计更加规范，一般符合3NF；而星型模型，一般采用降维的操作，利用冗余来避免模型过于复杂，提高易用性和分析效率。**

- **星型模型**

  核心是一个事实表及多个非正规化描述的维度表组成，**维度表之间是没有关联的，维度表是直接关联到事实表上的**，只**有当维度表极大，存储空间是个问题时，才考虑雪花型维度**，简而言之，最好就用星型维度即可

  当所有维表都直接连接到“ 事实表”上时，整个图解就像星星一样，故将该模型称为星型模型

  **星型架构是一种非正规化的结构，多维数据集的每一个维度都直接与事实表相连接，不存在渐变维度，所以数据有一定的冗余**，如在地域维度表中，存在国家 A 省 B 的城市 C 以及国家 A 省 B 的城市 D 两条记录，那么国家 A 和省 B 的信息分别存储了两次，即存在冗余。

  ![img](数据仓库.assets/668dfd6cf3787d3c479943acb4d77df0.png)

- **雪花模型**

  **星形模式中的维表相对雪花模式来说要大，而且不满足规范化设计**。**雪花模型相当于将星形模式的大维表拆分成小维表**，满足了规范化设计。然而这种模式在实际应用中很少见，因为这样做会导致开发难度增大，而数据冗余问题在数据仓库里并不严重

  可以认为雪花模型是星型模型的一个扩展，每个维度表可以继续向外扩展，连接多个子维度。

  当有一个或多个维表没有直接连接到事实表上，而是通过其他维表连接到事实表上时，其图解就像多个雪花连接在一起，故称雪花模型

  ![img](数据仓库.assets/5bac3b46d08989360d3409847f89f3c0.png)

- **星座模型**

  **前面介绍的两种维度建模方法都是多维表对应单事实表，但在很多时候维度空间内的事实表不止一个，而一个维表也可能被多个事实表用到**。在业务发展后期，绝大部分维度建模都采用的是星座模式。

  可以认为是多个事实表的关联或者是星型模型的关联，其实到了业务发展后期都是星座模型

  ![img](数据仓库.assets/f58d6605e7aaa53e72c8e5295973d101.png)



**应用场景**
**维度建模是面向分析场景而生，针对分析场景构建数仓模型，重点关注快速、灵活的解决分析需求，同时能够提供大规模数据的快速响应性能。**

针对性强，主要应用于数据仓库构建和OLAP引擎底层数据模型

**优点：**

- 方便使用，模型简单
- 适合大数据下的处理操作(其实就是`shuffle`)
- 适合OLAP操作(上钻下钻)
- 维度建模非常直观，紧紧围绕着业务模型，可以直观的反映出业务模型中的业务问题。不需要经过特别的抽象处理，即可以完成维度建模。
- 可扩展，维度模型是可扩展的。由于维度模型允许数据冗余，因此当向一个维度表或事实表中添加字段时，不会像关系模型那样产生巨大的影响，带来的结果就是更容易容纳不可预料的新增数据。

**缺点：**

- **数据冗余**，维度补全后造成的数据浪费
- 灵活性差，维度变化造成的数据更新量大(例如刷数据的时候，需要刷大量的表)
- 与典型的范式理论差异很大，如数据不一致，比如用户发起购买行为的时候的数据，和我们维度表里面存放的数据不一致

> 既然如此为什么还要使用范式建模呢，其实和我们使用的工具有关系

由于**在构建星型模式之前需要进行大量的数据预处理**，因此会导致大量的数据处理工作。而且，当业务发生变化，需要重新进行维度的定义时，往往需要重新进行维度数据的预处理。而在这些与处理过程中，往往会导致大量的数据冗余。

如果只是依靠单纯的维度建模，不能保证数据来源的一致性和准确性，而且在数据仓库的底层，不是特别适用于维度建模的方法。

**维度建模的领域主要适用于数据集市层，它的最大的作用其实是为了解决数据仓库建模中的性能问题**。维度建模很难能够提供一个完整地描述真实业务实体之间的复杂关系的抽象方法

### 2.7.4 总结

上述的这些方法都有自己的优点和局限性，在创建自己的数据仓库模型的时候，可以参考使用上述的三种数据仓库的建模方法，在各个不同阶段采用不同的方法，从而能够保证整个数据仓库建模的质量。

**方法论仅仅停留在理论层面上，落地实现的才真正决定了数仓设计的好坏**，当然再好的方法，只有在合适的阶段使用，才有意义，才能发挥它最大的价值。

### 附录

**数据仓库中的模式**

模式是数据库对象的集合，包括表、视图、索引和同义词。

应该根据数仓项目团队的需求和偏好来确定数仓应该使用哪个模式。

- `第三范式`

  经典的关系型数据库建模技术，通过规范化来最小化数据冗余。与星型模式相比，由于这种规范化过程3NF模式通常具有更多的表。例如，在图19-1中，orders和order items表包含的信息与图19-2中star模式中的sales表相似。

  **3NF模式通常用于大型数据仓库，特别是具有重要数据加载需求的环境，这些环境用于提供数据集市和执行长时间运行的查询。**

  3NF模式的主要优点是：

  - 提供中立的模式设计，独立于任何应用程序或数据使用注意事项
  - 可能比更规范化的模式（如星型模式）需要更少的数据转换

  图19-1给出了第三个标准格式模式的图形表示。

  

  ![image](数据仓库.assets/tdfgpdhy6kqj2_7d8b04c8ecd8493a8c26358c308c8632.jpeg)

  ​																					图19-1第三范式模式

  **优化第三范式查询**

  对3NF模式的查询通常非常复杂，涉及大量的表。因此，在使用3NF模式时，大型表之间的连接性能是一个主要考虑因素。

  3NF模式的一个特别重要的特性是分区连接。**应该对3NF架构中最大的表进行分区，以启用分区连接**。**这些环境中最常见的分区技术是针对最大表的组合范围哈希分区，其中最常见的连接键被选为哈希分区键。**

  在3NF环境中，并行性经常被大量使用，通常应该在这些环境中启用并行性。

- `星型模式`

  **星型模式可能是最简单的数据仓库模式。之所以称之为星型模式，是因为该模式的实体关系图类似于星型，点从中心表辐射。星的中心由一个大的事实表组成，星的点是维度表。**

  星型查询是事实表和许多维度表之间的联接。每个维度表都使用主键到外键的联接连接到事实表，**但维度表不会彼此联接**。优化器识别星形查询并为它们生成高效的执行计划。

  典型的事实表包含键和度量。例如，在sh示例架构中，事实表sales包含度量quantity_salled、amount和cost，以及键cust_id、time_id、prod_id、channel_id和promo_id。维度表是customers、times、products、channels和promotions。例如，products维度表包含事实表中显示的每个产品编号的信息。

  星型联接是维度表与事实表的外键联接的主键。

  星型模式的主要优点是：

  - 在最终用户分析的业务实体和模式设计之间提供直接直观的映射。
  - 为典型的星形查询提供高度优化的性能。
  - 被大量的商业智能工具广泛支持，这些工具可能预期甚至要求数据仓库模式包含维度表。

  **星型模式用于简单的数据集市和非常大的数据仓库。**

  图19-2给出了星型模式的图形表示。

  ![image](数据仓库.assets/tdfgpdhy6kqj2_1ee28c1bf5554b9dbf086e81b2c1a2bc.jpeg)

  ​																					图19-2 星型模式

- `雪花模式`

  **雪花模式是比星型模式更复杂的数据仓库模型，是星型模式的一种。它被称为雪花模式，因为模式的图表类似于雪花。**

  ![img](数据仓库.assets/tdfgpdhy6kqj2_26cf7283ecd14077a24e1dffa6212a97.png)

  **雪花模式规范化维度以消除冗余**。也就是说，维度数据已分组到多个表中，而不是一个大表中。例如，星型架构中的产品维度表可以规范化为雪花架构中的产品表、产品类别表和产品制造商表。**虽然这样可以节省空间，但会增加维度表的数量，并需要更多的外键联接。结果是查询更加复杂，查询性能降低。**图19-3展示了雪花模式的图形表示。

  ![img](数据仓库.assets/tdfgpdhy6kqj2_e99ab26b968341608015edd0434ac1fd.jpeg)

  ​																							图19-3雪花模式

## 2.8 问题总结

### 2.8.1 ODS与DWD区别？

问：还是不太明白 ods 和 dwd 层的区别，有了 ods 层后感觉 dwd 没有什么用了。

答：嗯，我是这样理解的，站在一个理想的角度来讲，如果 ods 层的数据就非常规整，基本能满足我们绝大部分的需求，这当然是好的，这时候 dwd 层其实也没太大必要。 但是现实中接触的情况是 ods 层的数据很难保证质量，毕竟数据的来源多种多样，推送方也会有自己的推送逻辑，在这种情况下，我们就需要通过额外的一层 dwd 来屏蔽一些底层的差异。

问：我大概明白了，是不是说 dwd 主要是对 ods 层做一些数据清洗和规范化的操作，dws 主要是对 ods 层数据做一些轻度的汇总?

对的，可以大致这样理解。

### 2.8.2 APP层干什么的？

问：感觉DWS层是不是没地方放了，各个业务的DWS表是应该在 DWD还是在 app?

答：这个问题不太好回答，我感觉主要就是明确一下DWS层是干什么的，如果你的DWS层放的就是一些可以供业务方使用的宽表表，放在 app 层就行。如果你说的数据集市是一个比较泛一点的概念，那么其实 dws、dwd、app 这些合起来都算是数据集市的内容。

问：那存到 Redis、ES 中的数据算是 app层吗?

答：算是的，我个人的理解，app 层主要存放一些相对成熟的表，能供业务侧使用的。这些表可以在 Hive 中，也可以是从 Hive 导入 Redis 或者 ES 这种查询性能比较好的系统中。

## 2.9 案例

[叮咚买菜基于Doris引擎的应用实践](https://zhuanlan.zhihu.com/p/627226600)

# 3. 数据湖

**本文来源微信公众号：大鱼的数据人生**

转载自：[到底什么是数据湖？全面解读数据湖的缘起、特征、技术、案例和趋势](https://blog.csdn.net/qq_36213530/article/details/121360407)

数据湖近几年迅速蹿红，今天笔者做一个综述，包括数据湖的缘起、数据湖的定义、数据湖的特征、数据湖的技术、数据湖的趋势和数据湖的案例六大部分，如果你要入门数据湖，一定要看一看。

注：文末列出了所有参考文献，方便你拓展阅读，并附有**《阿里云原生数据湖解决方案蓝皮书》**、**《华为DLI数据湖探索产品介绍》**PDF下载。

## 一、数据湖的缘起

10年前，Pentaho公司（一家开源BI公司）的CTO詹姆斯·迪克森在他的博客中第一次提出“数据湖”（Data Lake）的概念；10年后的今天，在业界“数据中台”大火的时代背景下，再来讨论“数据湖”，应该别有一番韵味。

1、从事务系统到数据仓库

要了解数据湖的来龙去脉，首先得提数据仓库的缘起[1][2]。

“数据仓库”，由比尔·恩门（Bill Inmon）于1990年提出，其被广泛接受的定义是，一个**面向主题的**、**集成的**、**相对稳定的**、**反映历史变化**的**数据集合**，用于支持管理决策，通常也被认为是决策支持型应用的必要条件。

此处的定义大多都是针对事务型数据系统而制定的。所谓事务型数据系统，是指记录业务交易的系统，这个名词先是在金融业，特别是银行实施信息化IT系统时使用的。例如银行的交易流水数据库，每分每秒都有大量的交易被数据库所记录并持久化的保存下来，其最小的颗粒度就是一笔“交易”。

但事务性数据系统存在诸多**劣势**：试想，如果一个银行的分行长想知道今天到目前为止共有多少现钞存款入账，那么系统就需要遍历今天截止到目前的所有交易行为，并筛选其中的存款行为进行汇总。查询交易的行为需要遍历当前系统的所有记录，因此当这一行为频率变高时，会对数据系统造成巨大的读取压力。

除开查询或分析任务对事务型数据系统造成的资源压力外，系统执行任务时，返回的结果只代表着任务开始运行那一刻的数据状态，假设执行查询任务消耗了1分钟，这1分钟内很有可能发生多次的交易撤销、额度修改，增加交易等行为。有些数据系统允许在读取数据的同时写入数据，那么**查询任务返回的结果并不能代表最新的状态**；有些数据系统则有“读锁”，即在读取数据的时候不允许写入数据，那么这个长达1分钟的查询任务会使得业务交易失败或者暂缓进入数据系统，如果其中发生业务中断，这些交易数据可能面临丢失的风险。

**当然，我们可以通过技术手段来避免或缓解事务型数据系统的不足，因此事务型的数据库并不是不能做业务分析，只是当决策者需要进行经营性的分析和决策时，大多数时候它并非最优方案。此时，数据仓库面向主题且便于分析的优势就体现出来了**：

数据仓库是面向分析的集成化数据平台，分析的结果给企业提供决策支持。企业中一般先有数据库，然后有数据仓库；可以没有数据仓库，但是不能没有数据库。

- **数据仓库本身不生产数据**

> 其分析的数据来自于企业各种数据源
> 企业中常见的数据源
> RDBMS关系型数据库--->业务数据
> log file--->日志文件数据
> 其他数据

**数据仓库本身也不消费数据**，其分析的结果给外部各种数据应用（`Data application`）来使用。

> `Data visualization （DV）`数据可视化
> `Data Report` 数据报表
> `Data Mining（DM）`数据挖掘
> `Ad-HOC` 即席查询

**数据仓库的特征**：

- **数据仓库是面向主题的**。相对于事务型系统将交易类型（存款）、交易币种（人民币或外币）、交易数值（存款额）以一条事务（Transcation）的方式存储，数据仓库通常会将一条事务中的不同信息拆分到不同的主题域中分别存储，例如交易类型表、交易币种表和交易额度表等。

  **理解**：

  > 面向主题性：在数仓中开展分析，首先确定分析的主题，然后基于主题寻找，采集跟主题相关的数据，一个分析的主题可以对应多个数据源。
  >
  > **例子**：
  >
  > 如果"产品分析"是一个分析领域，"产品分析"所涉及到的分析对象为商品、地域、时间、类别等，那么数仓的主题可以确定为商品主题、地域主题、时间主题、类别主题，"产品分析"可以作为一个**主题域**。
  >
  > 所以，这里的主题我觉的可以理解成一个分析的维度，比如商品主题就是以商品为维度来分析商品的，比如销售总额，销售量，等等。
  >
  > ![img](数据仓库.assets/v2-af946f7bf94319a05606148cc8a06a01_720w.webp)

  **主题和主题域**：

  > 主题上面讲了，这里主要讲主体域。
  >
  > 我理解就是将多个不同的主题划分到一类。这一类主题就属于这一主题域。
  >
  > 主题域的划分方法：
  >
  > - 按照所属业务系统划分
  >
  >   ![img](数据仓库.assets/v2-36b6009b4ae193de01aab31f060e15c5_720w.webp)
  >
  > - 按照业务(功能模块/业务线)或业务过程划分
  >
  >   ![img](数据仓库.assets/v2-f28205277aadded535384451a8f8d0cb_720w.webp)
  >
  > - 按照部门划分
  >
  >   ![img](数据仓库.assets/v2-87a74fd40afa23a7a8b224c3eea30ee7_720w.webp)

  数据域：

  > 数据域是指面向业务分析，将业务过程或者维度进行抽象的集合。为保障整个体系的生命力，数据域需要抽象提炼，并长期维护更新。在划分数据域时，既能涵盖当前所有的业务需求，又能让新业务在进入时可以被包含进已有的数据域或扩展新的数据域。数据域的划分工作可以在业务调研之后进行，需要分析各个业务模块中有哪些业务活动。我个人理解其实主题域和数据域差异不大，在实际过程中可以把主题域和数据域都当做一种域来处理了，不必纠结。
  >
  > ![img](数据仓库.assets/v2-49fd02b53f3a325bfb1efb5c76106b29_720w.webp)

- **数据仓库是集成的**。不同主题域中的信息之间以统一的ID，如交易流水号为标识进行链接。这样的好处是当分行长想知道今天到目前为止一共有多少人民币存款入账时，只需要先筛选出交易类型为存款，交易币种为人民币的交易流水号，再基于这些流水号去汇总交易额度，比起原先需要遍历全部交易记录后才能汇总的方式大大节约了系统资源的开销。

  理解：

  > 集成性：确定主题之后，需要把和主题相关的数据从各个数据源集成过来。因为同一个主题的数据可能来自不同的数据源，它们之间会存在着差异（异构数据）诸如字段同名不同意、单位不统一、编码不统一；因此在集成的过程中需要进行ETL（抽取、转换、加载）

- **数据仓库是相对稳定的**。数据仓库通常以时间窗口作为数据批量导入的分区，例如每一小时或一天从事务型系统导入一次数据，在下一次数据导入任务开始之前，系统处于一个相对稳定的状态，有利于进行经营性的业务分析。

  理解：

  > 

- **数据仓库是反映历史变化的**。正是由于通常数据仓库中的数据是基于预先设定好的时间窗口从事务型系统中获取数据，无论是一分钟、一小时还是一天、一周，它都是可以反映数据整体历史变化的，分行长可以清楚地知道今天银行的人民币存款入账环比昨天增长或减少了多少，同比上个月的今天又发生了什么变化。

  理解：

  > 时变性：数仓是一个持续维护建设的东西。站在时间的角度，数仓的数据成批次变化更新。一天一分析（T+1）、一周一分析（T+7）等（上述所讲的更多偏向于离线数仓，当下还有比较火的实时数仓）

- 不可更新性：数仓上面的数据几乎没有修改操作，都是分析的操作。数仓是分析数据规律的平台，不是创造数据规律的平台。（注意：改指的数据之间的规律不能修改。当下发现有些时间也是需要修改的，数据校正。数据缓慢变化）

因此，比起事务型的数据系统，数据仓库能更有效地对业务数据进行统计分析，无论是在提高效率、稳定性还是降低资源成本上都有其优势，所以被广为接受而大行其道。



2、从数据仓库到数据集市

后来，数据仓库领域的大师Ralph Kimball又演化出“维度建模”的概念，认为数据仓库是一系列数据集市的集合。**如果说数据仓库中包含着许多不同的主题域，那么数据集市可以理解为主要面向业务应用的单一主题域**。

比如，分行长可以建设面向存储部门的、专门提供存款数据的“存款数据集市”，面向商业贷款部门的“贷款数据集市”，面向信用卡部门的“信用卡数据集市”等，其数据都源自数据仓库，但数据集市的汇总程度更高、更注重业务表示。例如“环比存款增长率”这个指标在数据仓库中可能表示为“上月存款额”和“本月存款额”两个不同的数值，而在数据集市或者数据仓库的“集市层”中，就表示为计算后的一个数值，可以直接被业务所用而无需再做多余的计算。



3、数据湖的由来

数据湖最早是由Pentaho的创始人兼CTO， 詹姆斯·迪克森，在2010年10月纽约Hadoop World大会上提出来的。当时Pentaho刚刚发布了Hadoop的第一个版本。在这样的一个大背景下，可以合理的猜测，当时James Dixon提出数据湖的概念，是为了推广自家的Pentaho产品以及Hadoop的。

Pentaho是个BI分析组件。当时的BI分析主要是基于数据集市（Data Mart）的。数据集市的建立需要事先识别出感兴趣的字段、属性，并对数据进行聚合处理。这样BI分析面临两个问题：

（1）只使用一部分属性，这些数据只能回答预先定义好（pre-determined）的问题。

（2）数据被聚合了，最低层级的细节丢失了，能回答的问题被限制了。

而基于Hadoop的BI分析，可以解决这个问题——把所有数据都原样存在Hadoop中，后面需要的时候再来取用。**如果说数据集市、数据仓库里面是瓶装的水——它是清洁的、打包好的、摆放整齐方便取用的；那么数据湖里面就是原生态的水——它是未经处理的，原汁原味的。数据湖中的水从源头流入湖中，各种用户都可以来湖里获取、蒸馏提纯这些水（数据）**。

接下来发生的事件让数据湖的内涵获得了拓展，这是詹姆斯·迪克森没想到的。

2011年，福布斯在文章《Big Data Requires a Big, New Architecture》中报道了“data lake”这个词，并给出了数据仓库与数据湖的对比：**数据仓库的数据在被集成时就会被预先分类，并以最优的方式进行存储，以支撑特定的分析；但在大数据时代，我们从源系统抽取数据时可能无法明确知道这些数据的价值，因此无法给出一个最优的存储方式**。

例如，分行长从交易系统中将所有的数据都抽取过来，但并不知道业务部门想做什么类型反映业务历史的变化。因此建议将这些数据先保存在一个海量的数据库中。由于数据来源的格式五花八门而且会越存越多，因此这个数据库需要具备容易访问且存储成本低（允许硬件资源扩容的成本而尽可能降低其他成本，例如软件使用费用、人工维护费用等）的特性，需要进行分析时，再来组织和筛选所需数据，这个数据库就是数据湖（Data Lake）。

彼时的数据湖概念更多地是关于当企业在处理海量异构的数据时，如何在数据产生实际的应用价值之前，为海量数据构建一个易访问且成本低的存储方式，和数据资产化、资产服务化等当下热点名词并没有太大关系。

2014年，福布斯杂志上刊登了一篇名为《The Data Lake Dream》的文章，文章作者EddDumbill描述了数据湖的愿景：

（1）融合所有数据，解决系统间数据孤岛、各类应用统一访问问题；

（2）数据可获取性提高，应用部署时间缩短；

（3）具有弹性的分布数据处理的平台，能同时支撑批量和实时数据操作处理和分析；

（4）数据湖增加安全和管控层面的功能；

（5）重视集中、自动的元数据管理和入湖标准，避免成为没有价值的数据。

数据湖可以解决数据孤岛问题这种特性似乎也挺符合数据湖的理念的。各种数据源都汇聚到一个湖里，自然就解决了数据孤岛问题，但这应该并不是James的本意。从他后来的blog中可以看出，他所认为的数据湖是这样的：

（1）数据湖应该是来源于单一的数据源；

（2）你可以有多个数据湖；

（3）如果存储来自多个系统的数据并对他们进行关联，那么这不是数据湖，而是由多个数据湖填充而成的水上花园（Water Garden）

不过，创始人怎么想已经不重要了……目前大家普遍认为，解决数据孤岛是数据湖的一大特点，毕竟这是一个看上去很美好的事。

然后云计算的“XaaS”的风潮助推了数据湖的兴起，例如软件即服务（SaaS，Software as a Service），平台即服务（PaaS，Platform as a Service），基础设施即服务（Iaas，Infrastructure as a Service）。从这个时候开始，单纯的数据湖就朝向一个“平台级的方案”而演进。

数据湖从本质上来讲，是一种企业数据架构方法。物理实现上则是一个数据存储平台，用来集中化存储企业内海量的、多来源，多种类的数据，并支持对数据进行快速加工和分析。

**目前Hadoop是最常用的部署数据湖的技术，以前这个概念国内谈的少，但绝大部分互联网公司都已经有了，国内一般把整个HDFS叫做数据仓库（广义），即存放所有数据的地方，而国外一般叫数据湖（data lake）。**

真正将数据湖推而广之的是亚马逊[AWS](https://so.csdn.net/so/search?q=AWS&spm=1001.2101.3001.7020)。AWS 构筑了一套以 S3 为中心化存储、Glue 为元数据服务，E-MapReduce、Athena 为引擎的开放协作式的产品解决方案，AWS 之后，各个云厂商也纷纷跟进数据湖的概念，并在自己的云服务上提供类似的产品解决方案。

2014年6月26日，西瓜哥在“高端存储知识”公众号发表了一篇文章”你知道数据湖泊（DATA LAKE)吗?”一文，首次把数据湖这个概念引入中国。由于那时还没有标准的翻译，为了和数据仓库术语字数对齐，翻译成数据湖泊。

现在，数据湖已经得到快速发展，很多厂商都推出了自己的解决方案。当前商业的数据湖产品包括**AWS数据湖、华为数据湖、阿里云数据湖、Azure数据湖，开源的数据湖产品包括delta、iceberg和hudi等等**。



## 二、数据湖的定义

下面是维基等组织给出的数据湖的早期定义，随着数据湖的发展，其实数据湖早已不是原来的“湖”的概念了：

Wikipedia：

数据湖是一类存储数据自然/原始格式的系统或存储，通常是对象块或者文件。数据湖通常是企业中全量数据的单一存储。全量数据包括原始系统所产生的原始数据拷贝以及为了各类任务而产生的转换数据，各类任务包括报表、可视化、高级分析和机器学习。

数据湖中包括来自于关系型数据库中的结构化数据（行和列）、半结构化数据（如CSV、日志、XML、JSON）、非结构化数据（如email、文档、PDF等）和二进制数据（如图像、音频、视频）。

数据沼泽是一种退化的、缺乏管理的数据湖，数据沼泽对于用户来说要么是不可访问的要么就是无法提供足够的价值。



AWS：

数据湖是一个集中式存储库，允许您以任意规模存储所有结构化和非结构化数据。您可以按原样存储数据（无需先对数据进行结构化处理），并运行不同类型的分析 – 从控制面板和可视化到大数据处理、实时分析和机器学习，以指导做出更好的决策。



微软：

Azure的数据湖包括一切使得开发者、数据科学家、分析师能更简单的存储、处理数据的能力，这些能力使得用户可以存储任意规模、任意类型、任意产生速度的数据，并且可以跨平台、跨语言的做所有类型的分析和处理。数据湖在能帮助用户加速应用数据的同时，消除了数据采集和存储的复杂性，同时也能支持批处理、流式计算、交互式分析等。

数据湖能同现有的数据管理和治理的IT投资一起工作，保证数据的一致、可管理和安全。它也能同现有的业务数据库和数据仓库无缝集成，帮助扩展现有的数据应用。

Azure数据湖吸取了大量企业级用户的经验，并且在微软一些业务中支持了大规模处理和分析场景，包括Office 365, Xbox Live, Azure, Windows, Bing和Skype。Azure解决了许多效率和可扩展性的挑战，作为一类服务使得用户可以最大化数据资产的价值来满足当前和未来需求。



## 三、数据湖的特征

笔者结合多方的观点[2][3][4][5][6][7]，给出数据湖的六大核心特征，从这些特征看，数据湖更是一种企业数据架构方法：

（1）“保真性”。数据湖中对于业务系统中的数据都会存储一份“一模一样”的完整拷贝。与数据仓库不同的地方在于，数据湖中必须要保存一份原始数据，无论是数据格式、数据模式、数据内容都不应该被修改。在这方面，数据湖强调的是对于业务数据“原汁原味”的保存。同时，数据湖应该能够存储任意类型/格式的数据，包括结构化、半结构化和非结构化数据。

（2）“灵活性”：如果数据仓库属于计划经济，那数据湖就属于市场经济[7]，数据仓库强调“写入型schema”，  “写入型schema”背后隐含的逻辑是数据在写入之前，就需要根据业务的访问方式确定数据的schema，然后按照既定schema，完成数据导入，带来的好处是数据与业务的良好适配；但是这也意味着数仓的前期拥有成本会比较高，特别是当业务模式不清晰、业务还处于探索阶段时，数仓的灵活性不够。数据湖强调的是“读取型schema”，背后的潜在逻辑则是认为业务的不确定性是常态：我们无法预期业务的变化，那么我们就保持一定的灵活性，将设计去延后，让整个基础设施具备使数据“按需”贴合业务的能力。

（3）“可管理”：数据湖应该提供完善的数据管理能力。既然数据要求“保真性”和“灵活性”，那么至少数据湖中会存在两类数据：原始数据和处理后的数据。数据湖中的数据会不断的积累、演化。因此，对于数据管理能力也会要求很高，至少应该包含以下数据管理能力：数据源、数据连接、数据格式、数据schema（库/表/列/行）。同时，数据湖是单个企业/组织中统一的数据存放场所，因此，还需要具有一定的权限管理能力。

（4）“可分析”：从批处理、流式计算、交互式分析到机器学习，各类计算引擎都属于数据湖应该囊括的范畴。一般情况下，数据的加载、转换、处理会使用批处理计算引擎；需要实时计算的部分，会使用流式计算引擎；对于一些探索式的分析场景，可能又需要引入交互式分析引擎。随着大数据技术与人工智能技术的结合越来越紧密，各类机器学习/深度学习算法也被不断引入，例如TensorFlow/PyTorch框架已经支持从HDFS/S3/OSS上读取样本数据进行训练。因此，对于一个合格的数据湖项目而言，计算引擎的可扩展/可插拔，应该是一类基础能力。

（5）“可追溯”：数据湖是一个组织/企业中全量数据的存储场所，需要对数据的全生命周期进行管理，包括数据的定义、接入、存储、处理、分析、应用的全过程。一个强大的数据湖实现，需要能做到对其间的任意一条数据的接入、存储、处理、消费过程是可追溯的，能够清楚的重现数据完整的产生过程和流动过程。

（6）“可存储”：数据湖需要提供足够用的、可扩展的统一数据存储能力，理论上，数据湖本身应该内置多模态的存储引擎，以满足不同的应用对于数据访问需求（综合考虑响应时间/并发/访问频次/成本等因素）。但是，在实际的使用过程中，数据湖中的数据通常并不会被高频次的访问，而且相关的应用也多在进行探索式的数据应用，为了达到可接受的性价比，数据湖建设通常会选择相对便宜的存储引擎（如S3/OSS/HDFS/OBS），并且在需要时与外置存储引擎协同工作，满足多样化的应用需求。



## 四、数据湖的技术

数据湖要解决的核心问题是高效的存储各类数据并支撑上层应用，传统的数据湖一般采用HDFS为存储引擎，但在实际应用中面临着难以克服的问题，这直接催生了**delta**、**iceberg**和**hudi**[11]三大开源数据湖方案，虽然它们开始的时候是为了解决特定的应用问题的，但最终促成了数据湖特征的统一。

1、Delta

以`Databricks`推出的delta为例，它要解决的核心问题基本上集中在下图：



![图片](数据仓库.assets/8c5efb6ace8f8229c3c1f1846d2d97ec.png)



在没有delta数据湖之前，Databricks的客户一般会采用经典的lambda架构来构建他们的流批处理场景。以用户点击行为分析为例，点击事件经Kafka被下游的Spark Streaming作业消费，分析处理（业务层面聚合等）后得到一个实时的分析结果，这个实时结果只是当前时间所看到的一个状态，无法反应时间轴上的所有点击事件。所以为了保存全量点击行为，Kafka还会被另外一个Spark Batch作业分析处理，导入到文件系统上（一般就是parquet格式写HDFS或者S3，可以认为这个文件系统是一个简配版的数据湖），供下游的Batch作业做全量的数据分析以及AI处理等。

**这套方案其实存在很多问题** :

第一、批量导入到文件系统的数据一般都缺乏全局的严格schema规范，下游的Spark作业做分析时碰到格式混乱的数据会很麻烦，每一个分析作业都要过滤处理错乱缺失的数据，成本较大；

第二、数据写入文件系统这个过程没有ACID保证，用户可能读到导入中间状态的数据。所以上层的批处理作业为了躲开这个坑，只能调度避开数据导入时间段，可以想象这对业务方是多么不友好；同时也无法保证多次导入的快照版本，例如业务方想读最近5次导入的数据版本，其实是做不到的。

第三、用户无法高效upsert/delete更新历史数据，parquet文件一旦写入HDFS文件，要想改数据，就只能全量重新写一份的数据，成本很高。事实上，这种需求是广泛存在的，例如由于程序问题，导致错误地写入一些数据到文件系统，现在业务方想要把这些数据纠正过来；线上的MySQL binlog不断地导入update/delete增量更新到下游数据湖中；某些数据审查规范要求做强制数据删除。

第四、频繁地数据导入会在文件系统上产生大量的小文件，导致文件系统不堪重负，尤其是HDFS这种对文件数有限制的文件系统。

在Databricks看来，以下四个点是数据湖必备的：



![图片](数据仓库.assets/fb91dd5f35a5d4daaae1e1a36a3c03c3.png)



事实上, Databricks在设计delta时，希望做到流批作业在数据层面做到进一步的统一(如下图)。业务数据经过Kafka导入到统一的数据湖中（无论批处理，还是流处理），上层业务可以借助各种分析引擎做进一步的商业报表分析、流式计算以及AI分析等等。



![图片](数据仓库.assets/55b9d237a450534819a907aa547e1cb1.png)



2、Hudi

Uber的业务场景主要为：将线上产生的行程订单数据，同步到一个统一的数据中心，然后供上层各个城市运营同事用来做分析和处理。在2014年的时候，Uber的数据湖架构相对比较简单，业务日志经由Kafka同步到S3上，上层用EMR做数据分析；线上的关系型数据库以及NoSQL则会通过ETL（ETL任务也会拉去一些Kakfa同步到S3的数据）任务同步到闭源的Vertica分析型数据库，城市运营同学主要通过Vertica SQL实现数据聚合。当时也碰到数据格式混乱、系统扩展成本高（依赖收Vertica商业收费软件）、数据回填麻烦等问题。后续迁移到开源的Hadoop生态，解决了扩展性问题等问题，但依然碰到Databricks上述的一些问题，其中最核心的问题是无法快速upsert存量数据。



![图片](数据仓库.assets/bda985b3122fe1e389bc92f3ffc35104.png)



如上图所示，ETL任务每隔30分钟定期地把增量更新数据同步到分析表中，全部改写已存在的全量旧数据文件，导致数据延迟和资源消耗都很高。此外，在数据湖的下游，还存在流式作业会增量地消费新写入的数据，数据湖的流式消费对他们来说也是必备的功能。所以，他们就希望设计一种合适的数据湖方案，在解决通用数据湖需求的前提下，还能实现快速的upsert以及流式增量消费。



Uber团队在Hudi上同时实现了Copy On Write和Merge On Read 的两种数据格式，其中Merge On Read就是为了解决他们的fast upsert而设计的。简单来说，就是每次把增量更新的数据都写入到一批独立的delta文件集，定期地通过compaction合并delta文件和存量的data文件。同时给上层分析引擎提供三种不同的读取视角：仅读取delta增量文件、仅读取data文件、合并读取delta和data文件。满足各种业务方对数据湖的流批数据分析需求。

最终，我们可以提炼出Uber的数据湖需求为如下图，这也正好是Hudi所侧重的核心特性。



![图片](数据仓库.assets/f878cb3b8e3e7d37164492fad053c464.png)



3、Iceberg

Netflix的数据湖原先是借助Hive来构建，但发现Hive在设计上的诸多缺陷之后，开始转为自研Iceberg，并最终演化成Apache下一个高度抽象通用的开源数据湖方案。Netflix用内部的一个时序数据业务的案例来说明Hive的这些问题，采用Hive时按照时间字段做partition，他们发现仅一个月会产生2688个partition和270万个数据文件。他们执行一个简单的select查询，发现仅在分区裁剪阶段就耗费数十分钟。

他们发现Hive的元数据依赖一个外部的MySQL和HDFS文件系统，通过MySQL找到相关的parition之后，需要为每个partition去HDFS文件系统上按照分区做目录的list操作。在文件量大的情况下，这是一个非常耗时的操作。同时，由于元数据分属MySQL和HDFS管理，写入操作本身的原子性难以保证。即使在开启Hive ACID情况下，仍有很多细小场景无法保证原子性。另外，Hive Memstore没有文件级别的统计信息，这使得filter只能下推到partition级别，而无法下推到文件级别，对上层分析性能损耗无可避免。最后，Hive对底层文件系统的复杂语义依赖，使得数据湖难以构建在成本更低的S3上。

于是，Netflix为了解决这些痛点，设计了自己的轻量级数据湖Iceberg。在设计之初，作者们将其定位为一个通用的数据湖项目，所以在实现上做了高度的抽象。虽然目前从功能上看不如前面两者丰富，但由于它牢固坚实的底层设计，一旦功能补齐，将成为一个非常有潜力的开源数据湖方案。



总体来说，Netflix设计Iceberg的核心诉求可以归纳为如下：



![图片](数据仓库.assets/24de9459aedf99e5fc3c0e5704c19bfa.png)



**因此，数据湖并不是炒作的新概念，而是来源于应用的驱动，delta、iceberg和hudi这类新技术实际是介于上层计算引擎和底层存储格式之间的一个中间层，我们可以把它定义成一种“数据组织格式”**，Iceberg 将其称之为“表格式”也是表达类似的含义。它与底层的存储格式（比如 ORC、Parquet 之类的列式存储格式）最大的区别是，它并不定义数据存储方式，而是定义了数据、元数据的组织方式，向上提供统一的“表”的语义。它构建在数据存储格式之上，其底层的数据存储仍然使用 Parquet、ORC 等进行存储。



![图片](数据仓库.assets/27d43e8a0ae61d8f899c364df73e3c71.png)

delta、iceberg和hudi诞生于不同公司，需要解决的问题存在差异，Iceberg 在其格式定义和核心能力上最为完善，但是上游引擎的适配上稍显不足；Hudi 基于 Spark 打造了完整的流式数据落地方案，但是其核心抽象较弱，与 Spark 耦合较紧；Delta Lake 同样高度依赖于 Spark 生态圈，与其他引擎的适配尚需时日，**虽然这三个方案在设计初衷上稍有不同，但实现的思路和提供的能力却非常相似，我们可以总结出数据湖技术需要具备的能力**：

（1）同时支持流批处理

（2）支持数据更新

（3）支持事务（ACID）

（4）可扩展的元数据

（5）支持多种存储引擎

（6）支持多种计算引擎

不同公司根据不同需求选择了不同的数据湖产品，比如阿里云的 DLA 团队选择 hudi 作为其底层数据湖存储引擎；腾讯选择了 iceberg 作为他们的数据湖存储引擎,比如文章《基于 Flink+Iceberg 构建企业级实时数据湖》[12]就介绍了腾讯的企业实时数据湖方案。



五、数据湖的趋势

1、服务模式演进趋势

下面是阿里云[3]给出的数据湖服务架构的演进过程，整体上可分为三个阶段：



![图片](数据仓库.assets/a490994579a08f683b1cba8c7620943e.png)



**第一阶段：自建开源Hadoop数据湖架构**，原始数据统一存放在HDFS系统上，引擎以Hadoop和Spark开源生态为主，存储和计算一体。缺点是需要企业自己运维和管理整套集群，成本高且集群稳定性差。

**第二阶段：云上托管Hadoop数据湖架构（即EMR开源数据湖）**，底层物理服务器和开源软件版本由云厂商提供和管理，数据仍统一存放在HDFS系统上，引擎以Hadoop和Spark开源生态为主。这个架构通过云上 IaaS 层提升了机器层面的弹性和稳定性，使企业的整体运维成本有所下降，但企业仍然需要对HDFS系统以及服务运行状态进行管理和治理，即应用层的运维工作。同时因为存储和计算耦合在一起，稳定性不是最优，两种资源无法独立扩展，使用成本也不是最优。

**第三阶段：云上数据湖架构（无服务器）**，即云上纯托管的存储系统逐步取代HDFS，成为数据湖的存储基础设施，并且引擎丰富度也不断扩展。除了Hadoop和Spark的生态引擎之外，各云厂商还发展出面向数据湖的引擎产品。如分析类的数据湖引擎有AWS Athena和华为DLI，AI类的有AWS Sagemaker。

这个架构仍然保持了一个存储和多个引擎的特性，所以统一元数据服务至关重要，如AWS推出了Glue，阿里云EMR近期也即将发布数据湖统一元数据服务。该架构相对于原生HDFS的数据湖架构的优势在于：

（1）帮助用户摆脱原生HDFS系统运维困难的问题。HDFS系统运维有两个困难：1）存储系统相比计算引擎更高的稳定性要求和更高的运维风险 2）与计算混布在一起，带来的扩展弹性问题。存储计算分离架构帮助用户解耦存储，并交由云厂商统一运维管理，解决了稳定性和运维问题。

（2）分离后的存储系统可以独立扩展，不再需要与计算耦合，可降低整体成本

（3）当用户采用数据湖架构之后，客观上也帮助客户完成了存储统一化（解决多个HDFS数据孤岛的问题）



2、技术架构演进趋势

**第一阶段：以Hadoop为代表的离线数据处理基础设施**。如下图所示，Hadoop是以HDFS为核心存储，以MapReduce（简称MR）为基本计算模型的批量数据处理基础设施。

![img](数据仓库.assets/b490d0119c0c4bdf83561d5e7a4d3d37.gif)

第二阶段：lambda架构。随着数据处理能力和处理需求的不断变化，越来越多的用户发现，批处理模式无论如何提升性能，也无法满足一些实时性要求高的处理场景，流式计算引擎应运而生，例如Storm、Spark Streaming、Flink等，如下图所示，整个数据流向自左向右流入平台。进入平台后一分为二，一部分走批处理模式，一部分走流式计算模式。无论哪种计算模式，最终的处理结果都通过服务层对应用提供，确保访问的一致性。



![图片](数据仓库.assets/2bcef921821770956ccce666a853105d.png)



第三阶段：Kappa架构。Lambda架构解决了应用读取数据的一致性问题，但是“流批分离”的处理链路增大了研发的复杂性。因此，有人就提出能不能用一套系统来解决所有问题。目前比较流行的做法就是基于流计算来做。流计算天然的分布式特征，注定了他的扩展性更好。通过加大流计算的并发性，加大流式数据的“时间窗口”，来统一批处理与流式处理两种计算模式。



![图片](数据仓库.assets/c852d7c3e90780e47796f04900e04d81.png)



3、湖仓一体的演进趋势

数据仓库的设计强调计划，而数据湖强调市场，更具灵活性，因此对于处于不同阶段的企业的效用是不一样的：

1、当企业处于初创阶段，数据从产生到消费还需要一个创新探索的阶段才能逐渐沉淀下来，那么用于支撑这类业务的大数据系统，灵活性就更加重要，数据湖的架构更适用。

2、当企业逐渐成熟起来，已经沉淀为一系列数据处理流程，问题开始转化为数据规模不断增长，处理数据的成本不断增加，参与数据流程的人员、部门不断增多，那么用于支撑这类业务的大数据系统，成长性的好坏就决定了业务能够发展多远。数据仓库的架构更适用。



![图片](数据仓库.assets/13a4fc4cd9bc661cadf0954f97e4a73e.png)



对企业来说，数据湖和数据仓库是否必须是一个二选一的选择题？是否能有一种方案同时兼顾数据湖的灵活性和云数据仓库的成长性，将二者有效结合起来为用户实现更低的总体拥有成本？阿里云提出了大数据架构新概念：湖仓一体。

何谓湖仓一体？

（1）湖和仓的数据/元数据无缝打通，互相补充，数据仓库的模型反哺到数据湖（成为原始数据一部分），湖的结构化应用知识沉淀到数据仓库

（2）湖和仓有统一的开发体验，存储在不同系统的数据，可以通过一个统一的开发/管理平台操作

（3）数据湖与数据仓库的数据，系统可以根据自动的规则决定哪些数据放在数仓，哪些保留在数据湖，进而形成一体化





六、数据湖的案例

1、AWS数据湖



![图片](数据仓库.assets/118c413393feee18c10647c16e1871e6.png)



AWS数据湖[8]基于AWS Lake Formation构建，AWS Lake Formation本质上是一个管理性质的组件，它与其他AWS服务互相配合，来完成整个企业级数据湖构建功能。上图自左向右，体现了数据沉淀、数据流入、数据计算、数据服务等步骤。

（1）**数据沉淀**：采用Amazon S3作为整个数据湖的集中存储，包含结构化和非结构化的数据，按需扩展/按使用量付费

（2） **数据流入**：元数据抓取、ETL和数据准备AWS将其单独抽象出来，形成了一个产品叫AWS GLUE，GLUE基本的计算形式是各类批处理模式的ETL任务，任务的出发方式分为手动触发、定时触发、事件触发三种

（3）**数据处理**：利用AWS GLUE进行批处理计算模式之外，也可以使用Amazon EMR进行数据的高级处理分析，或者基于Amazon EMR、Amazon Kinesis来完成流处理任务

（4）**数据分析**：数据通过Athena/Redshift来提供基于SQL的交互式批处理能力，通过 Amazon Machine Learning、Amazon Lex、Amazon Rekognition进行深度加工



2、华为数据湖



华为数据湖基于DLI Serverless[9]构建，DLI完全兼容Apache Spark、Apache Flink生态和接口，是集实时分析、离线分析、交 互式分析为一体的Serverless大数据计算分析服务。可以看到，DLI相当于是AWS的Lake Formation、GLUE、EMR（Flink&Spark）、Athena等的集合，承担了所有的数据湖构建、数据处理、数据管理、数据应用的核心功能。

为了更好的支持数据集成、规范设计、数据开发、数据质量监控、数据资产管理、数据服务等数据湖高级功能，华为云提供了DAYU智能数据湖运营平台[10]，DAYU涵盖了整个数据湖治理的核心流程，并对其提供了相应的工具支持，如下图所示。



![图片](数据仓库.assets/47d3867df6fd291311218c75a41a9c12.png)



3、阿里云数据湖

![图片](数据仓库.assets/7b0789f3e28ce4584b333f964e9d9b90.png)



阿里云DLA数据湖解决方案[4]如上图所示，DLA 核心在于打造云原生的服务与引擎，端到端解决基于 OSS 的管理、分析、计算问题，核心关键点如下。

（1）**数据存储**：采用OSS作为数据湖的集中存储，可以支撑EB规模的数据湖，客户无需考虑存储量扩容，各类型数据可以统一存储

（2）**数据湖管理**：面对 OSS 数据开放性带来的管理及入湖困难，DLA的Formation组件具备元数据发现和一键建湖的能力，DLA提供Meta data catalog组件对于数据湖中的数据资产进行统一的管理，无论数据是在“湖中”还是在“湖外”，比如利用元数据爬取功能，可以一键创建 OSS 上的元数据信息，轻松自动识别 CSV/JSON/Parquet 等格式，建立好库表信息，方便后续计算引擎使用

（3）**数据分析和计算**：DLA提供了SQL计算引擎和Spark计算引擎两种。无论是SQL还是Spark引擎，都和Meta data catalog深度集成，能方便的获取元数据信息。基于Spark的能力，DLA解决方案支持批处理、流计算和机器学习等计算模式

（4）**在数据集成和开发上：**阿里云的数据湖解决方案提供两种选择：一种是采用dataworks完成；另一种是采用DMS来完成。无论是选择哪种，都能对外提供可视化的流程编排、任务调度、任务管理能力。在数据生命周期管理上，dataworks的数据地图能力相对更加成熟。

阿里云DLA解决方案的另一个特色在于“**基于云原生的湖仓一体化**”。传统的企业级数据仓库在大数据时代的今天，在各类报表应用上依然是无法替代的；但是数仓无法满足大数据时代的数据分析处理的灵活性需求。

因此，阿里云推荐数据仓库应该作为数据湖的上层应用存在：即数据湖是原始业务数据在一个企业/组织中唯一官方数据存储地；数据湖根据各类业务应用需求，将原始数据进行加工处理，形成可再次利用的中间结果；当中间结果的数据模式（Schema）相对固定后，DLA可以将中间结果推送至数据仓库，供企业/组织开展基于数仓的业务应用。阿里云在提供DLA的同时，还提供了云原生数仓（原ADB），DLA和云原生数仓在以下两点上深度融合。

（1） 使用同源的SQL解析引擎。DLA的SQL与ADB的SQL语法上完全兼容，这意味着开发者使用一套技术栈即能同时开发数据湖应用和数仓应用。

（2） 都内置了对于OSS的访问支持。OSS直接作为DLA的原生存储存在；对于ADB而言，可以通过外部表的能力，很方便的访问OSS上的结构化数据。借助外部表，数据可以自由的在DLA和ADB之间流转，做到真正的湖仓一体。



![图片](数据仓库.assets/1d9fa4db38f2f3034f5bd93b666ef7f7.png)





**结语**

在写这篇文章之前，笔者对于数据湖的理解是零碎的，不成体系的，通过这次归纳总结，我大致能理解数据湖的来龙去脉，希望对你也有所帮助。



## 五、参考文献：

[1]腾讯研究院  数据湖，比“数据中台”更需要重视的概念

https://www.huxiu.com/article/380785.html

[2]歌湾汐云 数据湖详解 

https://www.jianshu.com/p/dc510ec49f53

[3]阿里云 数据湖 VS 数据仓库之争？阿里提出大数据架构新概念：湖仓一体 

https://developer.aliyun.com/article/775390

[4]阿里云 “数据湖”：概念、特征、架构与案例 

https://zhuanlan.zhihu.com/p/145671783

[5]阿里云社区  数据湖 | 一文读懂Data Lake的概念、特征、架构与案例 

https://cloud.tencent.com/developer/article/1683057

[6]InfoQ AWS 数据湖十年，云计算老大哥的磨刀之路 

https://www.infoq.cn/article/0bpzikj7qgxst91khhue

[7]傅一平 与数据同行 数据湖与数据仓库的根本区别，在于前者是“市场经济”，而后者是“计划经济”  

https://mp.weixin.qq.com/s/N_K-Rqgmtok0hg-yPLHmcw

[8]石秀峰 谈数据 探秘亚马逊AWS数据湖 

https://zhuanlan.zhihu.com/p/257851584

[9]什么是DLI 

https://support.huaweicloud.com/productdesc-dli/dli_07_0001.html

[10]什么是智能数据湖运营平台

https://www.huaweicloud.com/zhishi/dayu2.html

[11]openinx 深度对比delta、iceberg和hudi三大开源数据湖方案 

https://zhuanlan.zhihu.com/p/110748218

[12]基于 Flink+Iceberg 构建企业级实时数据湖  

https://juejin.cn/post/6913805958360039437

## 六、案例

参考文章：http://www.taodudu.cc/news/show-5282800.html?action=onClick

华为数据湖（如图5-2所示）是逻辑上对内外部的结构化、非结构化的原始数据的逻辑汇聚。数据入湖要遵从**6项入湖标准**，基于6项标准保证入湖的质量，同时面向不同的消费场景提供两种入湖方式，满足数据消费的要求。

![图片](数据仓库.assets/3fb9f56e0acd33a715712b9c7510730f.png)

**华为数据湖的特点**：

- **逻辑统一**

  不同的数据类型、业务区域等会由多个不同的物理存储构成，通过统一的元数据进行定义、拉通和管理。

- **类型多样**

  湖中存放多种类型的数据：结构化、半结构化、非结构。如对内的系统数据、业务交易数据、xml、html、音频、视频、web服务日志等。

- **原始记录**

  华为数据湖是对原始数据的汇聚，不对数据做任何转换、清洗、加工等处理，保留数据最原始的特征。

**华为数据湖的6项标准**：

- **明确数据Owner**

  常由数据产生流程的Owner担任

- **发布数据标准**

  入湖数据要有相应的业务数据标准

- **认证过的数据源**

  确保数据从正确的数据源头入湖

- **定义数据密级**

  确保湖中的数据能够充分地共享，同时不会发生信息安全问题

- **数据质量评估**

  数据入湖不需要对数据进行清洗，但是要对质量进行评估，让数据消费人员了解数据的质量情况

- **元数据注册**

  将入湖数据的业务元数据和技术元数据进行关联。如业务属性与表字段的对应关系。

  通过联接业务元数据和技术元数据，支持业务人员通过业务语义来快速搜索湖中的数据，降低数据消费的门槛。

**数据入湖的方式**，以逻辑数据实体为粒度入湖（逻辑数据实体？指描述一个业务对象在某方面特征的一组属性集合，先简单理解为一条完整事实数据）：

- **物理入湖**

  将原始数据复制到湖中，包括批集成、DRS、消息和流集成等方式。

- **虚拟入湖**

  指原始数据不在湖中进行物理存储，而是通过建立虚拟表（我理解是类似于外表）的集成方式实现入湖，实时性更强，大批量的数据操作会加大对源系统的负载压力

**数据入湖的技术手段**：

- **批量集成**

  如ETL、ELT、FTP等工具，集成作业每小时或每天定时调度。

  适用于要进行复杂数据清理、转换且数据量较大的场景。

  不适用于低数据延迟和高灵活性的场景。

- **数据复制同步DRS**

  使用基于日志的CDC捕获数据变更，实时获取数据

  适用于需要高可用性和对数据源影响小的场景

  不适用于各种数据结构，存在复杂数据清理、转换的场景

- **消息集成**

  通过API捕获或提取数据

  适用于处理不同数据结构以及需要高可靠性和复杂转换的场景

  不适用于处理大量数据的场景

- **流集成**

  流数据的采集和处理

  适用于数据实时集成需求，处理每秒数万、数十万，甚至数百万个事件流的场景

  不适用于需要复杂数据处理和转换的场景

- **数据虚拟化**

  适用于低数据延迟，高灵活性和临时模式的消费场景

  不适用于需要处理大量数据的场景

**五种入湖技术的对比**

![图片](数据仓库.assets/806521c253d649b36c75a9a50213803b.png)

**数据入湖有推和拉**两种情况：

![图片](数据仓库.assets/d054e121361b76cf1edac11bff1738be.png)

### 结构化数据入湖

结构化数据是指由二维表结构来逻辑表达和实现的数据，严格遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。

结构化数据入湖过程包括：数据入湖需求分析及管理、检查数据入湖条件和评估入湖标准、实施数据入湖、注册元数据（如图所示）。

 

![图片](数据仓库.assets/5a9c941580e9bbd7a3174a3a34b706cd.png)

#### （1）数据入湖需求分析及管理

对于规划驱动入湖场景而言，由对应的数据代表基于数据湖的建设规划，输出入湖规划清单，**清单包含主题域分组、主题域、业务对象、逻辑实体、业务属性、源系统物理表和物理字段等信息。**

 对于需求驱动入湖场景而言，由数据消费方的业务代表提出入湖需求，并提供数据需求的业务元数据和技术元数据的信息，包括业务对象、逻辑实体、业务属性对应界面的截图。

#### （2）检查数据入湖条件和评估入湖标准

**1）检查数据源准备度**

数据有源是数据入湖的基本前提，数据源准备度检查不仅需要源系统的IT团队提供源系统的数据字典和数据模型并检查源系统的物理表规范度，而且需要数据代表评估源系统的数据质量。

**2）评估入湖标准**

上述6个标准。

#### （3）实施数据入湖

不要求历史数据，小批量数据且实时性要求高的场景使用**虚拟入湖**

要求历史数据，大批量数据且实时性要求不高的场景使用**物理入湖**

#### （4）注册元数据

元数据是公司的重要资产，是数据共享和消费的前提，为数据导航和数据地图建设提供关键输入。对元数据进行有效注册是实现上述目的的前提。

### 非结构化数据入湖

#### （1）非结构化数据管理的范围

数据文件本身+非结构化数据的元数据信息（包括标题、格式、owner、标签等），便于用户对非结构化数据的检索和消费。

无格式的文本、各类格式文档（如xml、html等）、图像、音频、视频等多样异构数据。

![图片](数据仓库.assets/19ced0e56b2dd46b2bb3eecf8a475d37.png)

#### （2）非结构化数据入湖的4种方式

非结构化数据入湖包括基本特征元数据入湖、文件解析内容入湖、文件关系入湖和原始文件入湖4种方式，**其中基本特征元数据入湖是必选内容**，后面三项内容可以根据分析诉求选择性入湖和延后入湖

![图片](数据仓库.assets/8674ae65e0ee03543a55f5cae9f82ae9.png)

- **基本特征元数据入湖**

  数据内容仍存于源系统，湖中仅存非结构化数据的基本特征元数据

  非结构化数据的基本特征类属性

  ![图片](数据仓库.assets/16cb19a4d4528bf76f144b94cbd0d674.png)

- **文件解析内容入湖**

  对源文件内容解析，数据内容仍存于源系统，湖中仅存解析后的内容增强元数据

- **文件关系入湖**

  原始文件仍存于源系统，湖中仅存文件的关系等内容增量元数据

- **原始文件入湖**

  从源端把原始文件搬入湖中存储，并进行全生命周期管理

# 4. 数据治理

华为云数据治理方法论：https://support.huaweicloud.com/dgm-dataartsstudio/dataartsstudio_09_0001.html

Q. 数据治理为什么不是从业务系统端开始规范，去推动？

**答**：

>  数据治理可以从源系统也可以从数据管理平台，前者成本高，但可以保持数据一致性, 但是有些系统太老了联系不到建站方 或者建站方根本不配合  从源头治理就实现起来很难了；后者容易实现，成本低，但是数据是不一致的。
>
> 从后往前推，就变成为了抓数据而抓数据，就可能填报，造假等等。从前往后，从业务出发，围绕真实的企业流程，数据收集起来再反馈业务，效果最好。

Q. 为什么需要数据治理？

**答**：

>  之前他们上了太多报表，有报表就上，命名又很类似，说实话连我都不知道那个报表的数据是怎么来的，什么口径，两个报表又有什么区别



参考文章：https://www.jianshu.com/p/8d33a37b79c6

## 背景

大数据平台早期是野蛮生长的，作业直接在终端提交运行，处于一种完全无管理的自由状态。在17年上线了内部的大数据平台后，用户开始逐渐在平台上进行数据管理，代码编写，作业管理等工作，但是资源治理依旧缺失。

随着业务及数据量的不断增加，集群扩容，存储和计算资源达到一定规模后，对大数据平台进行资源治理就非常必要了，

## 组件

### HDFS

#### 为什么需要治理

1. 财务预算高

   数据增长非常快，不干预的情况下日增能达到100T。在计算与存储没有分离的情况下，存储资源的不足就意味着需要购买新的机器，不仅成本非常高，还会造成计算资源使用率低下。

2. 集群负载高

   HDFS 虽然支持水平扩展，但是当集群到了一定规模，NameNode 就会成为瓶颈，其一为 NN 的内存瓶颈，其二为大量DN的心跳RPC请求带来的网络瓶颈，同时重启恢复时间也会变长。

3. 运维压力大

   频繁的扩容，即使有自动化工具的支持，也会给工程师带来一些低价值的工作。

#### 为什么难以推动

1. 在集群数据量级较小的情况下，以优先解决业务需求为主，增加机器远比开发一整套资源分析系统的成本要低。
2. 平台需要推动业务部门删除一些”僵尸数据“，但业务部门人数较多，以开发业务为核心，删除数据在他们看来优先级非常低。

#### 需要做什么

核心思想：控制增量，优化存量

1. 冷数据

   长期没有访问的数据，包括一些分析建模留下的中间数据，无用数据等。针对这部分数据，设计了一个资源浪费分的概念，根据数据目录大小绝对值和最后一次访问时间进行计算，该分数达到一定阈值后会对用户进行提醒，不操作则进行删除。

2. 碎片文件

   通过计算目录下每个文件的平均大小，平均大小小于某个阈值时会触发，进行合并压缩处理，可以参考 [Spark 小文件合并优化实践](https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Flsshlsw%2Farticle%2Fdetails%2F102718820)

3. 异常增长

   数据目录增长异常，可能是业务存在较大的变动或是用户的误操作导致，这种情况需要对用户进行预警。

4. 空间占用绝对值高

   使用更高压缩率的压缩算法，例如zstd。统计出日增长绝对值最高或者月环比 / 季环比较高的 team ，发送邮件给相应 team leader，要求给出解决方案。

5. 集群容量评估

   根据集群历史数据增长情况，评估目前的容量多久后需要进行扩容。

6. 数据生命周期

   所有的数据进行表化，上大数据平台，强制填写生命周期，例如物化的临时表生命周期为7天，到期后会自动删除，不需要主动进行管理。普通的数据表/分区生命周期到之前7天给用户发邮件/钉钉，用户可以选择续期或者直接过期删除。

#### 部分效果图

容量评估



![img](https:////upload-images.jianshu.io/upload_images/1832028-5210c645ed5391bd.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

2020042314233829.png

用户资源使用趋势



![img](https:////upload-images.jianshu.io/upload_images/1832028-d89099fc1b3b8fa8.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

20200423213916347.png

用户数据日增量



![img](https:////upload-images.jianshu.io/upload_images/1832028-4ef4aaa1e2ef9f80.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

20200423142316184.png

### SPARK & YARN

#### 为什么需要治理

1. #### 资源使用不平衡

   比较常见的情况是集群中内存被申请满了，但是 CPU 还有剩余。

2. 运行时间不稳定

   同个作业多次运行时间波动幅度大。

3. 资源滥用

   每个业务方都希望自己的作业能尽可能快的完成，导致资源被滥用，带来一些不必要的资源紧张。

#### 需要做什么

1. 作业资源统计分析

   现实的情况是大多数作业直接运行在大数据平台上，少数作业因为历史原因还在终端运行。

   - 终端的作业都是独享一个 Spark Application ，从 submit 到 shutdown 有一个完整的生命周期。
   - 大数据平台作业则分为独享和共享 Application 两种，独享和终端类似，共享的方式是一个作业由 Spark 的几个 job 组成。

   对于独享的任务，直接计算整个 application 运行期间消耗的 mem_seconds/core_seconds ，共享的任务资源使用则是通过该任务结束时间获得的 mem_seconds/core_seconds 减去开始时间的值获得。

   对于 Spark 作业，还可以通过 Listener 对 task 做进一步的分析，帮助优化应用资源使用。

2. 集群资源统计分析

   根据统计信息能获取当前 cpu/mem 使用较高的一些作业及用户，根据历史资源使用趋势可以更合理的安排作业的调度时间。

3. 内存及 cpu 使用控制
    [spark on yarn cgroup 资源隔离(cpu篇)](https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Flsshlsw%2Farticle%2Fdetails%2F81365050)
    [使用 jvm-profiler 分析 spark 内存使用](https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Flsshlsw%2Farticle%2Fdetails%2F83446951)

4. 作业数量/资源池限制

   在平台层面对用户/应用账号不同类型作业（schedule/dev/etc.）进行提交数量限制，对不同的应用分资源池进行约束。

#### 部分效果图

集群资源使用及作业 Top



![img](https:////upload-images.jianshu.io/upload_images/1832028-827f85f0785ef409.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

20200423141941621.png

集群当前状态



![img](https:////upload-images.jianshu.io/upload_images/1832028-ca6aec02e2710e1b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

2020042314184496.png

Spark任务诊断



![img](https:////upload-images.jianshu.io/upload_images/1832028-27ddfc612609031a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

20200423141331153.png

![img](https:////upload-images.jianshu.io/upload_images/1832028-d7833bcb44948ec1.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

20200423141346851.png

### 计费

对于普通用户来说，提供诸如 core_hour / mem_gb_hour / disk_gb_day 之类的单位过于抽象，很难意识到自己真正使用了多少资源，所以根据算法直接将物理资源折算成人民币，可以具体到每个任务运行花了多少钱。

Spark 计算时会同时申请 mem 和 cpu 资源，如果一台物理机内存被申请完了，cpu 资源也是无法使用的，所以根据物理机的配置折算成计算单元更为合理 1cu = (1C,5G)，最后会根据 cu 和存储占用进行综合计费。

通过计费的方式可以对资源进行更直观的展现：

1. 从用户的角度，可以知道自己的某个任务计算花了多少钱，某个表存储花了多少钱。
2. 从公司的角度，能清晰的从报表上看到哪几个部门用了多少钱，哪个Team用了多少钱。
3. 从业务的角度，根据资源的使用可以更好的评估投入产出比以及业务价值，让其更有动力去优化业务代码。

任务维度的计费



![img](https:////upload-images.jianshu.io/upload_images/1832028-19382f723cdede06?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

任务维度的计费

### 后记

18年上线后进行了四个月的跟踪观察，存量数据绝对值降低了20%，文件数量降低了 35%，增量数据增速降低了80%，集群整体的内存使用率提升了20%，同一作业的多次运行时间波动范围下降了50%。

在整个治理过程中，技术只是其中的一小部分，同时还需要从行政上进行辅助，否则效果将会大打折扣。

# 数据质量

参考文档：https://help.aliyun.com/document_detail/123969.html?spm=a2c4g.123968.0.0.26924e2aCKCiTO

数据质量是数据分析结论有效性和准确性的基础。要保证业务数据质量，首先您需要明确数据的消费场景和加工链路。

### 数据质量的评估

数据质量可以从完整性、准确性、一致性和及时性共四个角度进行评估，详情请参见[数据质量评估标准](https://help.aliyun.com/document_detail/116880.htm#concept-221766)。![img](../06%23云计算%23/overview.assets/p50681.png)在本教程中，您将学会通过数据质量风险监控，保证数据的完整性、准确性、一致性；通过数据及时性监控，保证数据的及时性。

- 完整性

  完整性是指数据的记录和信息是否完整、不缺失。数据的缺失包括数据记录的缺失（表行数异常）和记录中某字段信息的缺失（字段出现空值）。在本教程中，您需要重点关注数据的生产环节（MaxCompute外部表引用的表格存储数据）和加工环节（数据仓库CDM及ADS层）中表行数是否大于0、表行数波动是否正常以及字段是否出现空值或重复的情况。

- 准确性

  准确性是指数据记录中信息和数据是否准确、不存在错误或异常。例如，在本教程中，如果UV、PV数值小于0，则明显是错误数据。

- 一致性

  对于不同的业务流程和节点，同一份数据必须保持一致性。例如表`province`字段中如果有**浙江**、**ZJ**两种表述，在您**group by province**时会出现两条记录。

- 及时性

  及时性主要体现在最终ADS层的数据可以及时产出。为保证及时性，您需要确保整条数据加工链路上的每个环节都可以及时产出数据。本教程将利用DataWorks智能监控功能保证数据加工每个环节的及时性。

数据质量的管理流程包括业务数据资产定级、加工卡点、风险点监控和及时性监控，您可以构建属于自己的数据质量保障体系。

数据质量管理的流程图如下。![流程图](../06%23云计算%23/overview.assets/p96996.png)

数据的资产等级，可以根据数据质量不满足完整性、准确性、一致性、及时性对业务的影响程度进行划分。

数据等级定义如下：

- 毁灭性质：数据一旦出错，将会引起重大资产损失，面临重大收益损失等。标记为A1。
- 全局性质：数据直接或间接用于企业级业务、效果评估和重要决策等。标记为A2。
- 局部性质：数据直接或间接用于某些业务线的运营、报告等，如果出现问题会给业务线造成一定的影响或造成工作效率降低。标记为A3。
- 一般性质：数据主要用于日常数据分析，出现问题带来的影响极小。标记为A4。
- 未知性质：无法明确数据的应用场景。标记为Ax。

资产等级标记包含毁灭性质为A1、全局性质为A2、局部性质为A3、一般性质为A4、未知性质为Ax。重要程度为A1>A2>A3>A4>Ax。

数据质量风险监控主要针对数据的准确性、一致性和完整性。数据质量监控和数据资产等级对应，您可以根据以下因素细化您的监控配置，

- 监控分类：数据量、主键、离散值、汇总值、业务规则和逻辑规则。
- 监控粒度：字段级别、表级别。
- 监控层次：ODS、CDM、ADS三层数据，其中ODS和DWD层主要偏重数据的完整性和一致性。DWS和ADS层数据量较小、逻辑复杂，偏重数据的准确性。

以下为不同数据资产等级和数仓层次数据的数据质量监控建议，仅供参考。![img](../06%23云计算%23/overview.assets/p50862.png)



# 数据中台

参考文章：https://baijiahao.baidu.com/s?id=1711025777501089896

https://blog.csdn.net/qingzhuyuxian/article/details/124820177

## 什么是数据中台？

数据中台是指通过数据技术，对海量数据进行采集、计算、存储、加工，同时统一标准和口径。

数据中台把数据统一之后，会形成标准数据，再进行存储，形成大数据资产层，进而为大家提供高效服务。

数据中台不是一个产品或技术，而是一套"让企业把数据用起来"的机制。底层逻辑是以数字化的手段，将数据抽象为服务，为下游应用提供数据服务。

![img](数据仓库.assets/d5249e8e455fbce26918c458ac19be38.png)

我的理解：**数据中台是DT时代的大背景下，为实现数据快（快速）、准（准确）、省（低成本）赋能业务发展的目标，将企业的数据统一整合起来，基于Onedata方法论借助大数据平台完成数据的统一加工处理，对外提供数据服务的一套机制。**

## 为什么要有数据中台，即数据中台解决了什么问题？

1996年，美国加特纳集团第一次提出商业智能的概念，它是指通过一系列的技术和方法，将企业已有的数据转化为有用的信息，帮助企业制定经营分析决策。传统数仓是面向单一业务系统，主要实现面向事物的增删改查，不能满足复杂的数据分析场景，此时，数据仓库的概念应运而生了。

数据仓库之父比尔·恩门在 1991 年出版的《Building the Data Warehouse》中首次给出了数据仓库的完整定义：数据仓库是在企业管理和决策中面向主题的、集成的、与时间相关的，不可修改的数据集合。

2016年左右，随着互联网的高速发展，业务场景的不断增加，数据应用的需求越来越多，为快速响应业务的需求，很多企业都不同程度的存在烟囱式的开发模式，这种烟囱式的开发导致企业不同业务线的数据是割裂的，这就造成了数据的重复加工，导致研发效率、数据存储和计算资源的浪费，使大数据的应用成本越来越高，也带来指标口径不一致的问题。产生这些问题的根源在于数据无法共享，为解决这一问题，2016年，阿里率先提出“数据中台”的口号。数据中台的核心是：**避免数据的重复加工，通过数据服务化，提高数据的共享能力，赋能数据应用。**

总的来说，数据中台具备异构数据统一计算、存储的能力，同时让分散杂乱的数据通过规范化的方式管理起来。数据中台借鉴了传统数仓面向主题域的数据组织方式，基于维度建模理论，构建统一的数据公共层和应用层。**数据中台依赖于大数据平台完成数据研发全流程，同时增加了数据治理和数据服务化以及数据资产内容。**

数据中台出现之前，企业中可能会存在如下问题：

- 企业的各种信息系统无法做到**数据互通**
- 新平台产生的数据与传统模式下产生的数据也**无法互通**
- 企业IT架构变得更复杂，实现底层数据的互联互通也更加困难

通过数据中台整合分散在各个子系统的孤岛数据，快速形成数据服务能力，为企业的经营决策提供支撑。

## 数据中台的价值

**1 数据中台是企业数据化建设的基础设施**

数据中台解决了企业全域数据汇聚的问题，打通以往的数据孤岛，沉淀数据资产，实现数据之间的价值共通，可基于数据中台满足复杂的数据应用场景。

**2 提升数据质量**

数据中台基于`Onedata方法论`构建统一的公共层，保证了源头数据的一致性，且实现数据按照统一口径只加工一次，实现全局指标、标签的统一，大大提高数据质量。

**3 节约企业数据应用成本**

基于数据中台的元数据管理的数据血缘，可以实现数据投入产出比的评估，及时发现并下线低ROI的数据，也避免数据重复加工。由此降低数据的研发、存储和计算成本，降低企业数据应用成本。

比如，对于一些超过3个月未使用的报表，可以做下线处理，评估表的ROI，对于低ROI的报表及时下线处理。

**4 健全各部门协作机制**

利用系统化的解决方案配合一定的管理机制，实现业务人员、数据研发、产品经理、数据分析师等角色的高效协同，提升各角色之间的协作效率。

# 5. 数据湖和数据仓库区别

参考文章：https://developer.aliyun.com/article/1115585

## 5.1 数据湖永久保留所有数据

在开发数仓的过程中，要花费大量的时间来分析数据源、了解业务流程，分析数据内容，**目的是设计可用于报告的高度结构化的数据类型**。

此过程决定了哪些数据放入数仓，而哪些数据不要。**目的是简化数据模型（用于提高数仓的性能）**，并节省昂贵的磁盘存储。

数据湖保留所有数据：

- 数仓正在使用的数据
- 以后可能会使用的数据
- 可能永远都不会使用的数据

某些情况下，比如个人私密信息，为满足安全条款，数据湖坑要对此类数据的保留和删策略做出额外的考量。

## 5.2 数据湖支持所有数据类型

数仓一般由从事务系统中抽取的数据组成，如web服务器日志、传感器数据、社交网络数据。非传统数据源的数据在数仓中很可能会被忽略，但可能现在发现这类数据也有新用途了，那就需要重新分析数据、抽取数据、建模等等。

在数据湖中，保留所有的数据，而不管源头和结构。保持数据的原始形式。不应该允许对原始数据的任何更改，原始数据被认为是不可变的，需确保：

- 所有从原始数据向下转换的数据都可以重新生成；
- 特定情况下可以访问原始数据，如数据科学家
- 可以重新处理随时间变化的转换或算法，从而提高历史数据的准确性
- 时间点分析可以实现，数据存储支持历史报告

## 5.3数据湖适应变化，支持对早期原始数据的探索

**数仓**：在开发数仓时，花费了很多时间来设计数仓的结果，但当心的需求来了，要让数仓适应此变化，需要花费许多DW/BI团队资源，因为很可能当前数仓中并没有相关的数据，需要对这部分数据从ETL、存储、数据建模和管理进行重新设计。

**数据湖**：所有数据都以原始形式存储在湖中，有新需求时，开发人员可立即从湖中获取到原始数据，进行早期分析。探索结果被证明有用之后，可以对数据进行正式建模，将数据清理、转换、标准化、可重用性、自动化结合起来，通过数仓或类似的数据区域将结果扩展给其他受众。

**数据湖中的区域概念**：

![3ede856c673df3e5cefd215513cbcd41.png](数据仓库.assets/64zdtz4i6kwn2_ec1938c2bb7a4ebdbfaf5df04d5f44e6.png)

![b695c30f4d2c64727b894b8b53bb6bd0.png](数据仓库.assets/64zdtz4i6kwn2_43e3572fb7b94ee8b980a6b9203364dd.png)

**在设计原始数据区域时，应关注最优写性能，在设计被管理的数据区域时，重点关注数据发现的便利性和最优数据检索。**

   **1 原始数据**

   在原始和策划区域内组织数据时，应注意以下事项:

   •安全边界

   •时间分区

   •主题域

   •保密级别

   •数据访问的概率

   •数据保留政策

   •业主/数据管家/主题专家

   **2 数据目录**

   利用数据目录，为整个企业的数据源和报告提供可发现性和探索性，包括::

   •元数据

   •数据标签

   •数据分类

   •数据沿袭

   一个技巧是尽可能在实际数据本身中包含数据沿袭和相关元数据。例如:表示数据来源的源系统的列。

   **3 数据格式**

   决定数据格式是一种选择，需要考虑的因素包括:

   •与上游或下游系统的兼容性

   •文件大小和压缩级别

   •支持的数据类型

   •随着时间的推移处理模式变化

   •方便，易于使用，人的可读性

## 5.4数据湖实现物联网和近实时数据

将数据加载到数仓的数据在批处理模式下性能最大。随着数仓系统扩展到更大的解决方案，MPP系统和分布式特性使得提供接近实时的数据变得更加困难。

数据湖具有轻松获取数据的能力，可用于物联网相关的用例等。

## 5.5数据湖支持所有用户（如业务运营用户（数仓的使用者）、数据科学和高级分析）

**数仓**：运行类用户，希望获得报告，查看关键指标，如果在数据湖中则需要时间转换数据以提高可用性。

**数据湖**：提供了原始的未清理的、未转换的数据；提供了对多种结构的数据的更容易访问。数据科学家使用先进的分析工具和功能，如统计分析和预测建模。不必花费大量时间在获取和导入数据上。

## 5.6 案例：基于Azure技术实现数据湖

数据湖非常适合云服务，比如微软Azure云平台。在本文中，主要关注体系结构的数据存储层和数据处理层。

   **1、数据湖存储服务**

   设计数据湖时，首先要考虑的是数据存储。在决定哪个服务最适合用于数据存储时，有相当多的考虑事项。在不同的场景中同时使用Azure存储和Azure数据湖存储是很常见的。

![bff7b2b78a28bf11e88ab1d96a68bccf.png](数据仓库.assets/64zdtz4i6kwn2_38b754357cc34d11b6c3f6cd8da4495f.png)

  **2、数据湖计算服务**

   一旦存储中的数据可用，就会有一定数量的计算服务可用。

![2cc2bc571449c3b319d38b0cb84b42b5.png](数据仓库.assets/64zdtz4i6kwn2_29df2193c91844b598bae8974816ea35.png)

   由于存储中的数据可以跨各种计算服务重用，因此选择一个计算服务进行处理并不是一个非此即彼的命题。例如，可能有一个集群每天运行特定时间来处理数据处理操作，而另一个集群每天24小时运行来处理用户查询。通常，**计算服务的成本远远超过数据存储的成本**。

   数据湖中的数据也可以与数据仓库一起使用。这可以通过一个成熟的第三方数据虚拟化提供商实现。还有许多方法可以在数据湖和关系数据库之间执行远程联邦查询。

![d7bab39373d4c29444638e73cff7aa30.png](数据仓库.assets/64zdtz4i6kwn2_c758284c100e4981854fad6b1cd8c987.png)   

## 5.7 云数据湖成功的因素

  云数据湖需要考虑的点：

- 存储类型
- 一个数据湖 VS 多个数据湖
- 安全功能
- 数据编目、元数据和标记
- 弹性
- 客户端工具访问
- 通用计算服务集成
- 数仓集成
- 灾难恢复

## 总结

**数仓**

**数仓具有的属性**：

- 代表抽象的业务主体域
- 数据经过高度转换、清理和结构化
- 在定义数据的用途之前，数据不会被添加数仓中
- 通常遵循数仓先去`Ralph Kimball`和`Bill Inmon`定义的方法

**数仓的特点**：

在业务用户可以使用数据进行分析之前，需要进行大量的发现、规划、数据建模和开发工作。这种为用户消费准备数据的预先工作为**写时模式((Schema on Write)**。因为必须在加载数据之前定义模式。

**数仓重点提供**：

- 经过清理的、用户友好的结构化数据
- 可靠准确的数据
- 流程标准化
- 预定义的数据结构

**数据湖**

数据湖可以广泛存各种格式的数据，这与传统的数据库中充满规则、高度结构化的存储有明显的不同。

**数据湖的理念**：

立即存储数据、很少的限制，然后在使用（或读取）数据时，应严格的业务逻辑、类型检查和数据治理，这是**读时模式(Schema on Read)**。与关系型数据库的**写时模式**正相反。

**数据湖专注于提供**：

- 一个架构平台，可以容纳任何类型的数据，如IOT数据、人工生成的数据、传统运营的数据等。
- 数据获取的障碍更少
- 降低了拥有成本、允许长期保存原始的、细粒度的数据
- 不用考虑数据分析工作，直到直到价值和确定的需求

**读时模式（Schema on Read）**：例如，Hive对数据的验证并在不加载数据时进行，而在查询时进行。这称为“读时模式”（schema on read）。

**写时模式（Schema on Read）**：在传统数据库里，表的模式是在数据加载时强制确定的。如果在加载时发现数据不符合模式，则被拒绝加载数据。因为数据是在写入数据库是对照模式进行检查，因此这一设计有时被称为“**写时模式**”（[schema](https://so.csdn.net/so/search?q=schema&spm=1001.2101.3001.7020) on write）。

通常，数据湖的存储成本比数仓的存储成本更低。

数据湖可以作为归档存储，当很少需要的旧数据从数仓转移到数据湖，通常被称为`DW`中的**热数据**和数据湖中的**冷数据**。

# 6. OLAP VS OLTP

参考文章：https://blog.csdn.net/qq_35338741/article/details/115656726

OLAP（On-line Analytical Processing，联机分析处理）是在基于数据仓库多维模型的基础上实现的面向分析的各类操作的集合。可以比较下其与传统的OLTP（On-line Transaction Processing，联机事务处理）的区别来看一下它的特点：

![img](数据仓库.assets/20210413103925265.png)

OLAP的优势是基于数据仓库面向主题、集成的、保留历史及不可变更的数据存储，以及多维模型多视角多层次的数据组织形式，如果脱离的这两点，OLAP将不复存在，也就没有优势可言。

## OLAP的类型

　　首先要声明的是这里介绍的有关多维数据模型和OLAP的内容基本都是基于ROLAP，因为其他几种类型极少接触，而且相关的资料也不多。

**MOLAP(Multidimensional)**

　　 MOLAP的典型代表是：`Kylin`，MOLAP一般会根据用户定义的数据维度、度量（也可以叫指标）在数据写入时生成预聚合数据；Query查询到来时，实际上查询的是预聚合的数据而不是原始明细数据，在查询模式相对固定的场景中，这种优化提速很明显。

  MOLAP 的优点和缺点都来自于其数据预处理 ( pre-processing ) 环节。数据预处理，将原始数据按照指定的计算规则预先做聚合计算，这样避免了查询过程中出现大量的即使计算，提升了查询性能。

  但是这样的预聚合处理，需要预先定义维度，会限制后期数据查询的灵活性；如果查询工作涉及新的指标，需要重新增加预处理流程，损失了灵活度，存储成本也很高；同时，这种方式不支持明细数据的查询，仅适用于聚合型查询（如：sum，avg，count）。

  因此，**MOLAP 适用于查询场景相对固定并且对查询性能要求非常高的场景。**如广告主经常使用的广告投放报表分析。

**ROLAP(Relational)**

　　ROLAP的典型代表是：`Presto`，`Doris`，`Impala`，`GreenPlum`，`Clickhouse`，`Elasticsearch`，`Hive`，`Spark SQL`，`Flink SQL`...

数据写入时，ROLAP并未使用像MOLAP那样的预聚合技术；ROLAP收到Query请求时，会先解析Query，生成执行计划，扫描数据，执行关系型算子，在原始数据上做过滤(Where)、聚合(Sum, Avg, Count)、关联(Join)，分组（Group By)、排序（Order By）等，最后将结算结果返回给用户，整个过程都是即时计算，没有预先聚合好的数据可供优化查询速度，拼的都是资源和算力的大小。

ROLAP 不需要进行**数据预处理 ( pre-processing )**，因此查询灵活，可扩展性好。这类引擎使用 **MPP 架构** ( 与Hadoop相似的大型并行处理架构，可以通过扩大并发来增加计算资源 )，可以高效处理大量数据。但是当数据量较大或 query 较为复杂时，查询性能也无法像 MOLAP 那样稳定。所有计算都是即时触发 ( 没有预处理 )，因此会耗费更多的计算资源，带来潜在的重复计算。因此，**ROLAP 适用于对查询模式不固定、查询灵活性要求高的场景。**如数据分析师常用的数据分析类产品，他们往往会对数据做各种预先不能确定的分析，所以需要更高的查询灵活性。

**HOLAP(Hybrid)**

　　介于MOLAP和ROLAP的类型，我的理解是细节的数据以ROLAP的形式存放，更加方便灵活，而高度聚合的数据以MOLAP的形式展现，更适合于高效的分析处理。

　　另外还有WOLAP(Web-based OLAP)、DOLAP(Desktop OLAP)、RTOLAP(Real-Time OLAP)，具体可以参开维基百科上的解释——[OLAP](http://en.wikipedia.org/wiki/Online_analytical_processing)。

## OLAP的基本操作

我们已经知道OLAP的操作是以查询——也就是数据库的SELECT操作为主，但是查询可以很复杂，比如基于关系数据库的查询可以多表关联，可以使用COUNT、SUM、AVG等聚合函数。OLAP正是基于多维模型定义了一些常见的面向分析的操作类型是这些操作显得更加直观。

　　OLAP的多维分析操作包括：**钻取（Drill-down）**、**上卷（Roll-up）**、**切片（Slice）**、**切块（Dice）**以及**旋转（Pivot）**，下面还是以上面的数据立方体为例来逐一解释下：

[![OLAP](数据仓库.assets/OLAP.png)](http://webdataanalysis.net/wp-content/uploads/2010/08/OLAP.png) 

　　**钻取（Drill-down）**：在维的不同层次间的变化，从上层降到下一层，或者说是将汇总数据拆分到更细节的数据，比如通过对2010年第二季度的总销售数据进行钻取来查看2010年第二季度4、5、6每个月的消费数据，如上图；当然也可以钻取浙江省来查看杭州市、宁波市、温州市……这些城市的销售数据。

　　**上卷（Roll-up）**：钻取的逆操作，即从细粒度数据向高层的聚合，如将江苏省、上海市和浙江省的销售数据进行汇总来查看江浙沪地区的销售数据，如上图。

　　**切片（Slice）**：选择维中特定的值进行分析，比如只选择电子产品的销售数据，或者2010年第二季度的数据。

　　**切块（Dice）**：选择维中特定区间的数据或者某批特定值进行分析，比如选择2010年第一季度到2010年第二季度的销售数据，或者是电子产品和日用品的销售数据。

　　**旋转（Pivot）**：即维的位置的互换，就像是二维表的行列转换，如图中通过旋转实现产品维和地域维的互换。

## OLAP的优势

首先必须说的是，OLAP的优势是基于数据仓库**面向主题**、**集成的**、**保留历史**及**不可变更的数据存储**，以及**多维模型多视角多层次**的数据组织形式，如果脱离的这两点，OLAP将不复存在，也就没有优势可言。

### 数据展现方式

　　基于多维模型的数据组织让数据的展示更加直观，它就像是我们平常看待各种事物的方式，可以从多个角度多个层面去发现事物的不同特性，而OLAP正是将这种寻常的思维模型应用到了数据分析上。

### 查询效率

　　多维模型的建立是基于对OLAP操作的优化基础上的，比如基于各个维的索引、对于一些常用查询所建的视图等，这些优化使得对百万千万甚至上亿数量级的运算变得得心应手。

### 分析的灵活性

　　我们知道多维数据模型可以从不同的角度和层面来观察数据，同时可以用上面介绍的各类OLAP操作对数据进行聚合、细分和选取，这样提高了分析的灵活性，可以从不同角度不同层面对数据进行细分和汇总，满足不同分析的需求。

　　是不是觉得其实OLAP并没有想象中的那么复杂，一旦多维数据模型建成后，在上面做OLAP其实是一件很cool的事情。 ![;)](数据仓库.assets/icon_wink.gif)

### 常见OLAP引擎对比

参考文章：https://blog.csdn.net/qq_35338741/article/details/115656726

![img](数据仓库.assets/20210413105021907.png)

![img](数据仓库.assets/20210413105102868.png)

执行模型对比

![](数据仓库.assets/20210413105153297.png)

**总结**

1：sparksql,hivesql更擅长超大数据量离线分析，对时间和qps没什么要求的场景

2：presto和impala均为on hadoop的分析性框架，数据依赖于第三方（如hive），应该算是**对hql的加速工具**，更适合用于公司内部预测性分析的场景，对**实时性要求较高的实时查询不太擅长**

3：kylin对固定指标，固定维度数据进行预聚合，利用空间换时间。计算结果存储在hbase查询效率非常高，缺点就是维度指标比较固定，对于复查不确定性查询场景不太适合，不够灵活

每日使用最新维度对历史数据进行回溯计算，**回刷历史**。在Kylin的MOLAP模式下存在如下问题：

     1：历史数据每日刷新，失去了增量的意义。
     2：每日回溯历史数据量大
     3: 预计算的大量历史数据实际使用率低下，实际工作中对历史的回溯80%集中在近1个月左右，但为了应对所有需求场景，业务要求计算更长周期的历史。
     4: 不支持明细数据的查询。

4：doris属于ROLAP关系型分析数据库，不同于上面的分析框架，它具有分析属性也是一个mpp架构的数据库自身维护数据。查询非常快且非常灵活

5：clickhouse不依赖hadoop，查询延迟ms级，但是不擅长多表关联查询，不擅长高并发场景（QPS> 1000）。

6：Elasticsearch支持QPS 1000+

7：Druid支持QPS数千，不擅长多表关联查询

# 7. 湖仓一体

参考文章：https://cloud.tencent.com/developer/article/2066853

## 前言

这十多年大数据技术蓬勃发展，从市场的表现来看基于大数据的数据存储和计算是非常有价值的，其中以云数据仓库为主打业务的公司Snowflake市值最高（截止当前449亿美元），另一家以湖仓一体为方向公司Databricks估值或达380亿美元；各大伺机而动的云厂商也纷纷推出自己的数据湖、云数据仓库、湖仓一体产品。

大数据领域概念（术语）还是非常多的，大多数时候都是先射箭再画靶，先有的需求大家搞了一段时间，然后由一些权威人士提出一些概念（术语）用于描述，所以不能严格用数学的定义方式去框定这些概念（术语）的边界；且很多时候一个术语“形象”比“准确”更易传播，形象意味着易懂，准确意味着信息量巨大（参考数学定义）。建议可以从需求的角度去切入理解这些大数据概念和技术，不要过于追求准确的定义。

无论是数据湖还是数据仓库最后还是面向于解决用户的问题，用户要的其实是数据里的信息，依赖于湖和仓的**数据摄取**、**存储**、**计算**能力。主要是因为海量多元的数据，如果**用户数据小业务简单完全可以用本地Excel导入数据进行各种有效分析**。以下讨论数据湖、数据仓库、湖仓一体都是**基于用户的数据是海量且复杂多元的**。



![img](数据仓库.assets/qh1f28tzzn.png)

​																										数据流程

如上图，在一个复杂场景里，数据分析人员需要进行业务建模、数据建模；技术人员需要进行数据架构的设计、开发、维护；用户可以使用业务模型、数据模型后产生业务价值；App根据算法、模型、用户画像等提供功能和推荐。

## What: 什么是数据湖、数据仓库？

**说明一下，当前主流的数据湖技术对二进制数据（图片、音频等）不友好，文章上下文说的都是分析型（结构化、半结构化）数据。**

只要业务场景复杂数据多元化，无论是你基于任何一个存储框架也得存储各种各样的数据，然后你得有计算引擎可以计算这些数据；同时由于业务要求，你需要对数据进行实时分析。数据湖技术把上述的过程集成化、标准化了；在数据入湖一开始就对数据按照指定标准进行组织，支持流批一体，不同框架有不同的组织方式（对特定场景有优化），但是目的都差不多；入湖后，提供标准化的数据读取方式，支持各种MPP引擎的计算；因为数据提前组织过，所以写入性能下降，查询性能提升。所以你可能之前一直在用数据湖，只是没用到数据湖技术。

数据仓库在入库之前，一般需要进行数据建模；接着按照表的格式对数据进行标准化和表指定的存储引擎进行数据组织，此时可能会损失掉一些信息；计算层通常都会对存储引擎的数据结构进行优化，以此来获得极致的查询体验。日常我们在进行大数据架构的设计实现时，一般会做的比数据仓库限定的范围多，但是我们还是称为数据仓库，所以还是再次提一下，不要太追求准确的定义。

![img](数据仓库.assets/qscewushv0.png)

​																											湖仓对比，图片来自阿里云

## Why：业界为什么要做湖仓一体？

**我来形象地描述一下：集合两者的优势，像数据仓库一样管理的数据湖，像数据湖一样开放的数据仓库。**

从What描述中数据湖和数据仓库的描述可以看出，业内常用的大数据架构基本上就是湖仓一体，即拓宽的数据仓库的功能，也会主动的规范数据的存储和使用。业内目前分享出来的信息来看，主要还是为了替换掉老的**Lambda**和Kappa架构，想通过一个相对简单的架构进行降本提效。



![img](数据仓库.assets/yikelm9gt1.png)

​																									湖仓价值的交点，图片来自阿里云

## How：业界怎么做湖仓一体？

目前业内的湖仓一体的架构一般都叫基于某某数据仓库的湖仓一体架构，用户会把**热数据（频繁查询）放在数据仓库**中，无论在存储和计算上都有大量的优化，计算速度快、成本高；**冷数据放在数据湖中，计算慢、成本低**，当用户要查询时，直接通过数据仓库的计算层来远程访问数据湖格式的数据，许多架构中还会来临时扩容弹性计算节点来计算冷数据，避免热数据的高效查询受影响。



![img](数据仓库.assets/hrwmz0hbxf.png)

​																									湖仓一体冷热存储架构

如上图，近N天的热数据在常驻MPP计算层进行查询，数据变冷后转成数据湖存储格式入湖，后续由弹性MPP计算层对数据进行计算，一般冷数据次数频率较低。



![img](数据仓库.assets/yl0udcu9fz.png)

​																									湖仓一体存算分离架构

如上图，所有数据异步入湖，数据仓库的元数据会更新，用户查询时会缓存需要扫描的原始数据，通过缓存淘汰机制清理计算频率较低的数据。

真实业务场景可能是同一套架构里面会支持上述两种实现。也有一些湖仓一体的架构中没有数据仓库产品，仅用了**Presto作为查询加速**（火山引擎、Bilibili），不过整体架构大致也差不多。

**以下列举了业界实现的方案**

[**阿里云 MaxCompute + Hologres**](https://help.aliyun.com/document_detail/205439.htm?spm=a2c4g.11186623.0.0.786829ecVEGTPA#task-2045385)

![img](数据仓库.assets/hmxobixne7.png)

![湖仓一体02](数据仓库.assets/湖仓一体02.png)

**阿里云 EMR + Starrocks**

![img](数据仓库.assets/w85n09gmqn.png)

[**华为云 湖仓一体**](https://developer.huaweicloud.com/exhibition/DAYU.html)

![img](数据仓库.assets/jxcrtty2o6.png)

**字节跳动 基于Doris的湖仓一体探索**

![img](数据仓库.assets/du051nth59.png)

[**字节跳动-火山引擎 湖仓一体云服务**](https://www.volcengine.com/product/las)

![img](数据仓库.assets/uialb116bt.png)

[**bilibili 湖仓一体架构**](https://cloud.tencent.com/developer/article/2023509)

![img](数据仓库.assets/yr0wyukbvp.png)

[**Google BigLake**](https://cloud.google.com/bigquery/docs/biglake-intro)

![img](数据仓库.assets/tyzycqmrd0.png)

[**Amazon Lake House**](https://aws.amazon.com/cn/blogs/big-data/build-a-lake-house-architecture-on-aws/)

![img](数据仓库.assets/17rns1n835.png)

[**Azure Lake House**](https://docs.microsoft.com/zh-cn/azure/architecture/solution-ideas/articles/azure-databricks-modern-analytics-architecture)

![img](数据仓库.assets/6fdkq97cbb.png)

[SnowFlake Data Lake](https://www.snowflake.com/workloads/data-lake/)

![img](数据仓库.assets/xh8ys4dizm.png)

[快手流批一体数据湖构建实践](https://zhuanlan.zhihu.com/p/633075562)

## 总结

当前湖仓一体主要面向于解决用户数据量特别大且多元化的场景，**仓的作用在于提速**，**湖的作用在支持海量的数据并发写入和海量存储**；且设计者希望尽量降低架构的复杂度，提高效率。

以下个人评估，仅供参考：

1. SnowFlake在分析型数据场景下基本上就是天生的湖仓一体，优势巨大。
2. Doris/Starrocks的架构也会往Snowflake方向改进，潜力满满。
3. 基于Spark/Presto的湖仓一体，查询的效率会低于上述两种，但是可以作为补足上述的部分场景。

欢迎交流。

## 参考

1 多角度解析：数据湖 VS 数据仓库的根本区别。[链接](https://mp.weixin.qq.com/s/HOCb_-8m_fpvKyiLWXE5kA)

2 深度对比 Delta、Iceberg 和 Hudi 三大开源数据湖方案。[链接](https://cloud.tencent.com/developer/article/1936522)

3 2万字详解数据湖：概念、特征、架构与案例。[链接](https://mp.weixin.qq.com/s/0Iv2fUygX6b4uRqW_LeTrg)

4 详解数据湖，概念、特征、架构、方案、场景以及建湖全过程。[链接](https://mp.weixin.qq.com/s/KBZBybCNgCYv9H4BswUfjw)

5 4万字全面掌握数据库、数据仓库、数据集市、数据湖、数据中台。[链接](https://mp.weixin.qq.com/s/SQofNHNT5bKOhQOs_GgJSg)

6 大数据发展20年，“仓湖一体”是终局？[链接](https://mp.weixin.qq.com/s/eaGGMFDc-15rtNofKpWHFQ)

7 B站基于Iceberg的湖仓一体架构实践。[链接](https://mp.weixin.qq.com/s?__biz=Mzg3Njc0NTgwMg==&mid=2247484582&idx=1&sn=45d662b2cfb11dff8b1ea19be21ab963&chksm=cf2cc183f85b4895fd4bf429ea2d1d53d5090a3174b6ea93cda4af83e6ee14164af4c6ed8304&scene=178&cur_album_id=2329861166598127619#rd)

8 亚马逊湖仓一体。[链接](https://aws.amazon.com/cn/big-data/datalakes-and-analytics/?nc=sn&loc=1)

9 构建切实有效的湖仓一体架构。 [链接](https://cloud.tencent.com/developer/news/783255)



# 附录-大数据术语

### 主数据



### 元数据

可分为：

- 技术元数据

- 业务元数据

  描述主数据背后的业务含义，如：

  - 主题定义：每段ETL、表背后的归属业务主题
  - 业务描述：每段代码实现的具体业务逻辑
  - 标准指标：类似于BI中的语义层、数仓中的一致性事实；将分析中的指标进行规范化
  - 标准维度：同标准指标，对分析的各维度定义实现规范化、标准化

- 管理元数据

  管理领域相关，包括管理流程、人员组织、角色职责等。

### AdHoc

Ad Hoc查询,即席分析。实时要求非常高，要求写入即可查，更新即反馈，有即席查询需求，且资源较为充足，查询复杂度较低，适合实时数仓场景一：即席查询。即席查询通俗来说就是不确定应用的具体查询模式，先把数据存下来，后续支撑尽量多灵活性的场景
CU：Compute Unit，大数据相关的云产品中，1CU=1core 4GB

### TPC-C



### TPC-H



### TPC-DS



### 逻辑视图

视图是一个虚拟表(也可以认为是一条语句)，基于它创建时指定的查询语句返回的结果集。每次访问它都会导致这个查询语句被执行一次。

### 物化视图

物化视图是包括一个查询结果的数据库对象，它是远程数据的的本地副本，或者用来生成基于数据表求和的汇总表。为了避免每次访问逻辑视图都执行这个查询，可以将这个查询结果集存储到一个物化视图(也叫实体化视图)。物化视图与普通的视图相比的区别是物化视图是建立的副本，它类似于一张表，需要占用存储空间。**物化视图中的数据是在数据写入时计算，数据进行预计算提高了查询效率。**

### 雪花模型

### 离线计算/批处理

### 渐进式计算

### 实时计算/流处理

**什么是实时计算？**

数据的业务价值会随着时间的流逝而迅速降低，因此在数据发生后必须尽快对齐进行计算和处理。传统的大数据处理模型将在线事务处理（OLTP）和离线分析从时序上分开，以小时甚至是天为计算周期对当前数据进行处理。因此传统的大数据处理方式无法满足数据实时计算的需求，比如某些对数据处理时延较低的业务场景：

- 实时大数据分析
- 风控预警，（总不能在事件发生后，T+1才预警吧）
- 实时预测
- 金融交易

实时计算的三大特点：

- 实时（Realtime）且无界（Unbounded）的数据流

  按数据发生的时间顺序被实时计算作业订阅和消费。数据无限。

- 持续（Continous）且高效的计算

  事件触发式的计算

- 流式（Streaming）且实时的数据集成

  数据集成到其他系统，如计算结果可[持续]写入目标数据存储（如RDS等）。

**是什么是流数据？**

所有大数据的产生均可以看做是一系列离散事件，这些离散事件时一条条事件流或数据流。相对于离线数据，流数据的规模普遍较小。**流数据是数据源持续产生的数据**。

**实时计算（流处理）和批量计算（批处理）的差异**

- 批量计算

  批量的、高延时的、主动发起的计算。

  ```mermaid
  graph LR
  A["数据源"] -- "1、装载数据如ETL或OLTP" --> B["批量计算"] -- "3、返回结果,集成结果到其他系统" -->C["其他系统"]
  D["用户"]-- "2、主动发起计算作业" --> B
  ```

  

- 实时计算

  持续的、低延时的、事件触发的计算。

  ```mermaid
  graph LR;
  A["数据源"] -- "2、实时数据" --> B["流式数据存储"] -- "2、实时数据" --> C["流式计算"] -- "3、实时结果流投递到其他系统" --> D["其他系统"]
  E["用户"] -- "1、提交流式任务，是一种常驻任务" --> C
  ```

计算模型差别对比，详情内容如下表所示。

| 对比指标     | 批量计算                                 | 实时计算                                                   |
| :----------- | :--------------------------------------- | :--------------------------------------------------------- |
| 数据集成方式 | 预先加载数据。                           | 实时加载数据到实时计算。                                   |
| 使用方式     | 业务逻辑可以修改，数据可重新计算。       | 业务逻辑一旦修改，之前的数据不可重新计算（流数据易逝性）。 |
| 数据范围     | 对加载的所有或大部分数据进行查询或处理。 | 对滚动时间窗口内的数据或仅对最近的数据记录进行查询或处理。 |
| 数据大小     | 大批量数据。                             | 单条记录或几条记录的微批量数据。                           |
| 性能         | 几分钟至几小时的延迟。                   | 大约几秒或几毫秒的延迟。                                   |
| 分析         | 复杂分析。                               | 简单的响应函数、聚合和滚动指标。                           |

### 维度

维度是观察业务的角度，用来反映业务的一类属性。属性的集合构成了维度，维度的属性就是维度表中的列。如在分析交易过程是，可通过卖家、卖家、商品和时间等维度描述交易发生的环境。

### ODS

Operational Data Store

### DWD

Data Warehouse Detail

### DWS

Data WareHouse Summary

### ADS

Application Data Service

### DIM

### Lambda架构



### 传统数仓

也叫离线数仓。

### 实时数仓

实时数据仓库（Real-time Data Warehouse）是指能够实时地处理和分析数据，使得数据仓库中的数据是**最新的、最准确的**，并且可以**实时响应用户的查询和分析需求**的一种数据仓库系统。

![img](数据仓库.assets/v2-97bf5f6901f7f318837b69fc3fe800a7_720w.webp)

举一个例子，假设某家电商有一个传统数据仓库用于分析销售数据，该数据仓库每天从线上和线下渠道抽取销售数据，然后通过ETL工具进行清洗和转换，最终将数据加载到数据仓库中。**这种数据仓库的更新速度较慢，一般需要等待一天后才能看到前一天的销售数据。**

但是如果这家电商需要在**促销活动期间实时监控销售情况**，并根据销售情况进行实时调整促销策略，这时就需要一个实时数据仓库来支持实时的查询和分析。实时数据仓库可以实时地从线上和线下渠道获取销售数据，并及时更新到数据仓库中，从而能够**在秒级别响应用户的查询和分析需求**，帮助电商快速发现销售趋势和问题，并及时调整促销策略，提高促销效果。

### 湖仓一体

湖和仓是大数据架构中的两种设计取向。让数据和计算在湖和仓之间自由流动。湖侧重文件存储的灵活性（支持多种文件存储格式）；仓侧重数据使用效率、大规模下的数据管理。



### upsert

### ELK

logstash-elasticsearch-kibana，即ELK，数据的采集-加工-存储，主要应用在日志数据的分析、检索。

### EDW

TODO

### ETL

ETL ：`Extract-Transform-Load`，用于描述将数据从来源端经过抽取、转换、加载到目的端的过程。

### 业务板块

比数据域更高维度的业务划分方法，适用于庞大的业务系统。

### 维度

维度建模由Ralph Kimball提出。维度模型主张从分析决策的需求出发构建模型，为分析需求服务。维度是度量的环境，是我们观察业务的角度，用来反映业务的一类属性。属性的集合构成维度，维度也可以称为实体对象。例如，在分析交易过程时，可以通过买家、卖家、商品和时间等维度描述交易发生的环境。

### 属性（维度属性）

维度所包含的表示维度的列称为维度属性。维度属性是查询约束条件、分组和报表标签生成的基本来源，是数据易用性的关键。

### 度量

在维度建模中，将度量称为事实，将环境描述为维度，维度是用于分析事实所需要的多样环境。度量通常为数值型数据，作为事实逻辑表的事实。

### 指标

指标分为**原子指标**和**派生指标**。原子指标是基于某一业务事件行为下的度量，是**业务定义中不可再拆分的指标**，是具有明确业务含义的名词，体现明确的业务统计口径和计算逻辑，例如支付金额。

- 原子指标=业务过程+度量。如成交额。
- 派生指标=时间周期+修饰词+原子指标，派生指标可以理解为对原子指标业务统计范围的圈定。如最近一天全省厨具类目各商品销售总额。

#### 原子指标

原子指标中的度量和属性来源于多维模型中的维度表和事实表，与多维模型所属的业务对象保持一致，与多维模型中的最细数据粒度保持一致。原子指标中仅含有唯一度量，所含其它所有与该度量、该业务对象相关的属性，旨在用于支撑衍生指标的敏捷自助消费。如：零售门店数量(包含门店名称、门店等级等属性)。

#### 衍生指标

衍生指标是原子指标通过添加口径/修饰词、维度卷积而成，口径/修饰词、维度均来源于原子指标中的属性。例如：促销员门店覆盖率。

#### 复合指标

复合指标由一个或多个衍生指标叠加计算而成，其中的维度、口径/修饰词均继承于衍生指标（不能脱离衍生指标维度和口径/修饰词的范围，去产生新的维度和口径/修饰词）。

### 业务限定

统计的业务范围，筛选出符合业务规则的记录（类似于SQL中**where**后的条件，不包括时间区间）。

### 统计周期

统计的时间范围，例如最近一天，最近30天等（类似于SQL中**where**后的时间条件）。

### 统计粒度

统计分析的对象或视角，定义数据需要汇总的程度，可理解为聚合运算时的分组条件（类似于SQL中的**group by**的对象）。粒度是维度的一个组合，指明您的统计范围。例如，某个指标是某个卖家在某个省份的成交额，则粒度就是卖家、地区这两个维度的组合。如果您需要统计全表的数据，则粒度为全表。在指定粒度时，您需要充分考虑到业务和维度的关系。统计粒度常作为派生指标的修饰词而存在。

### 数据质量

### 数据集成

数据从A1、A2、A3处接入/集成到B处。

### 数据地图

以数据搜索为核心，通过可视化方式，综合反映有关数据来源、数量、分布、标准、流向、关联关系、数据质量。让用户找到数据、读懂数据、消费数据，致力于为用户提供高效率的数据消费产品。

### 数据资产

由企业拥有或者控制的，能够为企业带来未来经济利益的，以物理或电子的方式记录的数据资源。在企业中并非所有的数据都构成数据资产，数据资产是能够为企业产生价值的数据资源。



基本概念之间的关系和举例如下图所示。![img](../06%23云计算%23/overview.assets/p47282.png)![img](../06%23云计算%23/overview.assets/p58877.png)

### 宽表

含义：指**字段比较多的数据库表**。通常是指业务主体相关的指标、纬度、属性关联在一起的一张数据库表。
特点：宽表由于把不同的内容都放在同一张表，**宽表已经不符合三范式的模型设计规范**。
坏处：**数据有大量冗余**
好处：查询性能的提高和便捷
宽表的设计广泛应用于数据挖掘模型训练前的数据准备，通过把相关字段放在同一张表中，可以大大提供数据挖掘模型训练过程中迭代计算的消息问题。

### 主题（Subject）

是在较高层次上将企业信息系统中的数据进行综合、归类和分析利用的一个抽象概念，每一个主题基本对应一个宏观的分析领域。在逻辑意义上，它是对应企业中某一宏观分析领域所涉及的分析对象。例如“销售分析”就是一个分析领域，因此这个数据仓库应用的主题就是“销售分析”。

### 全量表

参考：https://blog.csdn.net/weixin_41812379/article/details/124878804

我理解应该分为：全量非分区表和全量分区表。

- 全量非分区表：则每次都是最新的全量数据覆盖原数据。
- 全量分区表：全量表每次更新都会记录全量数据，包括原全量数据和本次新增数据，即每个分区内的数据都是截至分区时间的全量总数据。注意：全量表中每个分区内都是截至分区时间的全量数据，原先分区的数据依然存在于表中，只是每次更新会在最新分区内再更新一遍全量数据。**好像也能叫快照表？？**

### 增量表

参考：https://blog.csdn.net/weixin_41812379/article/details/124878804

- 增量非分区表：每次往非分区表中写入新增的数据，而不覆盖原表。
- 增量分区表：增量表每次更新是在原表数据的基础上记录本周期内新增的数据，如上例，按天更新的流量表，每次更新只新增一天内产生的新数据。注意：每次新产生的数据是以最新分区增加到表中，原先的数据依然存在于表中。

### 拉链表

参考：https://zhuanlan.zhihu.com/p/578944929

```text
1）记录一个事物从开始，一直到当前状态的所有变化的信息；
2）每次上报的都是历史记录的最终状态，是记录在当前时刻的历史总量；
3）当前记录存的是当前时间之前的所有历史记录的最后变化量（总量）；
4）存量一般设计成拉链表（月报 - 常用、日报）；
5）关链时间可以是3000年，9999等比较大的年份,例如[2022-07-01,9999-12-31]
表示连续的状态，因为开始时间为2022-07-01，闭合时间为未知；
```

适用场景：

```text
1. 数据量比较大。
2. 表中的部分字段的值会被更新，比如用户的地址，银行利率，订单的状态等。
3. 需要查看某一个时间点或者时间段的历史快照信息，比如，查看利率在历史某一个时间点的状态。
4. 变化的比例和频率不是很大，比如，总共有1000万的会员，每天新增和发生变化的有10万左右。
5. 如果对这边表每天都保留一份全量，那么每次全量中会保存很多不变的信息，对存储是极大的浪费;
拉链历史表，既能满足反应数据的历史状态，又可以最大程度的节省存储。
```

### 快照表

参考：

按日分区，记录截止数据日期的全量数据。

(1) 快照表，有无变化，都要报告

(2) 每次上报的数据都是所有的数据(变化的+没有变化的)

(3) 一天一个分区

![图片](数据仓库.assets/6400.png)

### 即席查询Ad-Hoc

即席查询（Ad Hoc）是用户根据自己的需求，灵活的选择查询条件，系统能够根据用户的选择生成相应的统计报表。

即席查询与通常查询从SQL语句上来说，并没有本质的差别。它们之间的差别在于：

通常的查询在系统设计和实施时是已知的，是定制开发的；所以我们可以在系统实施时通过建立索引、分区等技术来优化这些查询，使这些查询的效率很高。
而即席查询是用户在使用时临时生产的，是用户自定义查询条件的；系统无法预先优化这些查询，所以即席查询也是评估数据仓库的一个重要指标。即席查询的位置通常是在关系型的数据仓库中，即在EDW（enterprisedatawarehouse，企业级数据仓库）或者ROLAP中。

### 数据立方体

参考文章：http://webdataanalysis.net/web-data-warehouse/data-cube-and-olap/

关于数据立方体（Data Cube），这里必须注意的是数据立方体只是多维模型的一个形象的说法。立方体其本身只有三维，但多维模型不仅限于三维模型，可以组合更多的维度，但一方面是出于更方便地解释和描述，同时也是给思维成像和想象的空间；另一方面是为了与传统关系型数据库的二维表区别开来，于是就有了数据立方体的叫法。所以本文中也是引用立方体，也就是把多维模型以三维的方式为代表进行展现和描述，其实上Google图片搜索“OLAP”会有一大堆的数据立方体图片，这里我自己画了一个：

[![Data-Cube](数据仓库.assets/Data-Cube.png)](http://webdataanalysis.net/wp-content/uploads/2010/08/Data-Cube.png)

### 多维数据模型

参考文章：http://webdataanalysis.net/web-data-warehouse/multidimensional-data-model/

#### 多维数据模型的定义和作用

　　多维数据模型是为了满足用户从多角度多层次进行数据查询和分析的需要而建立起来的基于事实和维的数据库模型，其基本的应用是为了实现`OLAP（Online Analytical Processing）`。

#### 多维数据模型实例

**事实表和维表**。事实表是用来记录具体事件的，包含了每个事件的具体要素，以及具体发生的事情；维表则是对事实表中事件的要素的描述信息。

![Star-Schemas](数据仓库.assets/Star-Schemas.png)

这是一个最简单的星形模型的实例。事实表里面主要包含两方面的信息：**维和度量**，维的具体描述信息记录在维表，事实表中的维属性只是一个关联到维表的键，并不记录具体信息；度量一般都会记录事件的相应数值，比如这里的产品的销售数量、销售额等。维表中的信息一般是可以分层的，比如时间维的年月日、地域维的省市县等，这类分层的信息就是为了满足事实表中的度量可以在不同的粒度上完成聚合，比如2010年商品的销售额，来自上海市的销售额等。

**优点：**

　　**多维数据模型最大的优点就是其基于分析优化的数据组织和存储模式。**举个简单的例子，电子商务网站的操作数据库中记录的可能是某个时间点，某个用户购买了某个商品，并寄送到某个具体的地址的这种记录的集合，于是我们**无法马上获取**2010年的7月份到底有多少用户购买了商品，或者2010年的7月份有多少的浙江省用户购买了商品？但是在基于多维模型的基础上，此类查询就变得简单了，只要在时间维上将数据聚合到2010年的7月份，同时在地域维上将数据聚合到浙江省的粒度就可以实现，这个就是OLAP的概念，之后会有相关的文章进行介绍。**我理解**，多维模型这种都是提前根据所需维度进行聚合好的，直接查询对应的结果表（一般在ads层）就可以获取结果数据，而OLTP需要临时再进行表关联、聚合。

**缺点：**

　　**多维模型的缺点就是与关系模型相比其灵活性不够，一旦模型构建就很难进行更改。**比如一个订单的事实，其中用户可能购买了多种商品，包括了时间、用户维和商品数量、总价等度量，对于关系模型而言如果我们进而需要区分订单中包含了哪些商品，我们只需要另外再建一张表记录订单号和商品的对应关系即可，**但在多维模型里面一旦事实表构建起来后，我们无法将事实表中的一条订单记录再进行拆分，于是无法建立以一个新的维度——产品维（假设实现并没有设计产品维度的情况下）**，只能另外再建个以产品为主题的事实表。

　　所以，在建立多维模型之前，我们一般会根据需求首先详细的设计模型，应该包含哪些维和度量，应该让数据保持在哪个粒度上才能满足用户的分析需求。

### 维度退化

将维度退化至事实表中，减少事实表和维表的关联。即将维度字段/值拼接到事实表中，变成宽表。

### 指标体系

TODO

### **交互式查询**

- Hive 非实时分析，底层数据为HDFS/OSS
- Presto 近实时分析，底层数据为HDFS/OSS
- Impala 近实时分析，底层数据为HDFS/OSS
- Hologres 实时分析，Hologres本身就可作为底层数据存储，也可为HDFS/OSS
- DLA 实时分析，TODO



### **商业智能（BI）工具**

Tableau
FineBI
FineReport
Yonghong BI
Quick BI
观远BI
网易有数BI

开源BI工具
Davinci
Superset

数据库管理工具
DBeaver
DataGrip
SQL Workbench/J

ETL工具
Kettle
Apache Airflow
Azkaban
怎么没有DataX了？？？

### 大数据组件

- zeppelin：数据查询WebUI
- superset：报表可视化